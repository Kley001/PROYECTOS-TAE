---
title: "Análisis, predicción y pronóstico de la accidentalidad en la ciudad de Medellín (2014-2021)"
author: "Jesus David Santos Montes, Kleider Stiven Vásquez Gómez, Daniel Andrés Toro Aguirre, Jelssin Donnovan Robledo Mena, Juan Esteban Carvajal."
date: "05/12/2021"
output: 
  html_document:
    theme: spacelab
    code_folding: hide
    code_download: yes
    df_print: paged
    toc: true
    toc_float: 
      colapse: false
    
    
      

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1. Introducción

<div style="text-align: justify"> La accidentalidad vial en la ciudad de Medellín, es un problema estructural que limita el crecimiento económico y social, que debe ser atacado con politicas y estrategias de corto, mediano y largo plazo, en donde el gobierno, los entes privados y la academia, deben aunar esfuerzos por encontrar soluciones que beneficien a la sociedad en general. <div/>

En el presente reporte, se busca contribuir a esas estrategías que permitan dar ideas o soluciones, para afrontar la problemática de la accidentalidad vial en la ciudad de Medellín, a través del análisis y la predicción de la accidentalidad en la ciudad, utilizando como insumo los datos proporcionados por la Alcaldía de Medellín en el portal [MeData](http://medata.gov.co/dataset/incidentes-viales), en donde se reportan los incidentes viales en la ciudad entre los años 2014 y 2020. 


-----------------------------------------------------------------------

## 2. Datos

<div style="text-align: justify">
La base de datos inicial, fue consultada el día 18/11/2021, en formato .CSV. Se usaron las herramientas de  Excel y R para el procesamiento de la base de datos.
Inicialmente, esta contenía 270.765 observaciones y 17 variables. Directamente en el excel, antes de iniciar con el procesamiento en R, se crean dos variables nuevas, las cuales son; `DIA_SEMANA` y `HORA`. Luego, se generan 19 variables en total.  Una vista previa de la primeras observaciones de la base de datos inicial es la siguiente:
<div/>


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#Librerias y paquetes
#install.packages("sp") #para rgdal
#install.packages("kableExtra") #para kable (tablas html)
#install.packages("plotly")

library(stringr); library(dplyr); library(rgdal); library(plyr); library(tidyverse); library(kableExtra); library(lubridate); library(ggplot2); library(plotly); library(ggpubr);library(dummies);
library(readxl);library(sf);library(GGally);library(car);library(MLmetrics);library(wordcloud);library(gplots);library(R.utils);library(tm);library(DescTools);library(raster);library(mclust);library(geosphere);library(NbClust);library(factoextra);library(vegan);library(qpcR);library(leaflet)


base <- read.csv("incidentes_viales.csv", dec=",", header=T,sep=";", encoding = "UTF-8")
#270765 datos y 18 variables, porque se crea la variable hora y día dentro de la base

```


```{r message=FALSE, warning=FALSE , echo=T}
head(base,n=5)
#coercionando fecha accidente a tipo date
base$FECHA_ACCIDENTE <- as.Date(base$FECHA_ACCIDENTE, format="%d/%m/%Y") 

#class(base$FECHA_ACCIDENTE)


#colSums(is.na(base)|base=="") #cuenta los vacios

#summary(base)
#str(base)

```


<div style="text-align: justify">Lo siguiente, será analizar detalladamente variable por variable en busca de observaciones faltantes, erróneas, particulares, entre otras y con esto se quiere eliminar las variables que no se consideren pertinentes para este análisis.<div/>

**AÑO:** año de ocurrencia del incidente. (2014 hasta 2016)  

**CBML:** código catastral que corresponde al código comuna, barrio, manzana, lote catastral de un predio.
Hallazgo: 18.156 vacíos, se tienen 962 registros más con caracteres extraños como: AUC1, AUC2, Inst_14, Inst_16, Inst_18, Inst_19, Sin Inf
SN01, para un total de 19.118 registros mal estructurados o vacíos.  

**CLASE_ACCIDENTE:** clasificación del IPAT sobre la clase de accidente de transito: choque, atropello, volcamiento, caida de ocupante, incendio, u otro (que no corresponde a las anteriores 5 clasificaciones, p. ej: sumersión).
Hallazgo: 6 datos vacíos, se cambiarán por "otro", pues no fueron reportados o se perdieron al momento de tomar la medición.


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}

# reemplazar datos vacios de la variable CLASE_ACCIDENTE

base$CLASE_ACCIDENTE <- ifelse(base$CLASE_ACCIDENTE == "","Otro",base$CLASE_ACCIDENTE) #Cambiar nivel vacio por "otro"

base$CLASE_ACCIDENTE <- iconv(base$CLASE_ACCIDENTE, from = "UTF-8", to = "ASCII//TRANSLIT") # Correcion tildes

```

**DISEÑO:** en la variable `DISEÑO` que es el sitio donde ocurrió el accidente( Cicloruta, Glorieta, Intersección, Lote o Predio, Paso a Nivel, Paso Elevado, Paso Inferior, Pontón, Puente, Tramo de via, Tunel, Via peatonal).
Hallazgo: se encuentran 1.148 vacíos, se reemplazarán los vacíos por "otro". 


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}

# Cambiar datos vacios de la variable DISENO y correccion de niveles
base$DISEÑO <- ifelse(base$DISEÑO == "","otro",base$DISEÑO) #Cambiar nivel vacio por no especificado
base$DISENO <- iconv(base$DISEÑO, from = "UTF-8",to="ASCII//TRANSLIT") #Quitar tildes


```


**BARRIO, COMUNA, NUMCOMUNA:**

BARRIO: barrio de ocurrencia del incidente vial. 

Hallazgos: 19.006 vacíos. Además de los vacíos, se tienen 1.822 registros adicionales con carácteres como: números entre 0 y 9.086, AUC1, AUC2, Inst, Sin Inf, Sin nombre. Para un total de 20.828 registros mal estructurados o vacíos.



COMUNA: denominación con la cual se identifica cada Comuna o Corregimiento.

Hallazgos: 12.798 vacíos. Se tienen 7.064 registros adicionales con carácteres como: No Georef, 0, In, AU, Sin Inf, SN. Para un total de 19862 registros mal estructurados o vacíos.


NUMCOMUNA: número de la comununa en la que ocurrió incidente vial. Hallazgos: se tienen 20.116 registros adicionales con carácteres como: AU, In, Sin Inf, SN.


**LOCATION:** fuente de información con la cual se realizó la geocodificación. Contiene la latitud y longitud. Posteriormente será separada en dos variables.


**X:** coordenada X en metros del accidente, en sistema de coordenadas MAGNA Medellin Local

**Y:** coordenada Y en metros del accidente, en sistema de coordenadas MAGNA Medellin Local

**NRO_RADICADO:** consecutivo que asigna UNE, según el orden de llegada de los expedientes para su diligenciamiento.

**MES:** mes de ocurrencia del incidente vial. Esta variable no se modifica.

**GRAVEDAD_ACCIDENTE:** clasificación del IPAT - Informe Policial de Accidentes de Tránsito, sobre la gravedad del accidente, corresponde al resultado más grave presentado en el accidente. Daños materiales "Sólo daños", accidente con heridos "Herido", accidente con muertos "Muerto". No indica cantidad. Hallazgo: esta variable contenía algunos carácteres extraños, estos se modifican y se restauran. 


**FECHA_ACCIDENTES:** fecha de los accidente (formato YYYY-MM-DD hh:mi:ss), proviene del IPAT - Informe Policial de accidentes de Tránsito


**FECHA_ACCIDENTE:** fecha del accidente, proviene del IPAT - Informe Policial de accidente de Tránsito. Esta variable posteriormente se elimina debido a que porporciona menos información que la variable `FECHA_ACCIDENTES`.


**EXPEDIENTE:** consecutivo que asigna UNE, según el orden de llegada de los expedientes para su diligenciamiento. Esta variable posteriormente se elimina.


**DIRECCION ENCASILLADA:** dirección encasillada que entrega el geocodificador. Esta variable se elimina.


**DIRECCION:** dirección donde ocurrió el incidente. Esta variable no se modifica.

**NRO_RADICADO:** consecutivo que asigna UNE, según el orden de llegada de los expedientes para su diligenciamiento. 

### 2.1. Integración con los datos de Geo medellín y depuración de vacíos

Con la variable CBML y creando una nueva variable con los 4 primeros dígitos de esta, podemos obtener la comuna y el barrio de las filas en donde estos datos se encuentren vacíos. Para eso usaremos un archivo proporcionado por [GEO medellín](https://geomedellin-m-medellin.opendata.arcgis.com/datasets/M-Medellin::limite-barrio-vereda-catastral/about), donde se registran  los nombres de barrios y comunas con su código (CBML). Lo siguiente, será cruzar los datos de incidentes viales y los datos de Geo medellín teniendo como variable  común el código y CBML.



```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}


catastro <- rgdal::readOGR(dsn = "D:/Users/Usuario/Desktop/UN/11. SEMESTRE XI/TAE/Limite_Barrio_Vereda_Catastral.shp", layer = "Limite_Barrio_Vereda_Catastral")


#quitamos los 962 datos de CBML que están errados ---> quedan 269803
base <- base[-which(base$CBML %in% c("AUC1","AUC2","Inst_14","Inst_16","Inst_18","Inst_19","Sin Inf","SN01")),]

#Creamos un nueva columna llamada CB en base que solo deja los primeros 4 digitos de CBML para buscarlos en la base de catastro y traer la comuna y el barrio de los que estén vacios.

base <- mutate(base, CB = str_sub(CBML,1,4))

#agregando un cero adelante a los CB y creando una nueva columna --> JCB
base <- mutate(base, JCB=ifelse(nchar(CB)==3,paste0("0", CB),CB),CB)

colnames(base)#nombres de columnas




#base unificada, se eliminan en total =  15794+962=16756 observaciones

base <- inner_join(base, dplyr::select(catastro@data,CODIGO,NOMBRE_COM,NOMBRE_BAR),
                  by = c("JCB" = "CODIGO")) #quedan 254009 datos


#Quitar repetidos por el inner_join

base <- base %>%     #convirtiendo en factor para ver mejor los únicos
  mutate(NRO_RADICADO = as.factor(NRO_RADICADO))
radicados_duplicados <- base$NRO_RADICADO[duplicated(base$NRO_RADICADO)]

radicados_duplicados  #verificar duplicados
registros_rad_dup <- base %>% 
  
  filter(NRO_RADICADO %in% radicados_duplicados) %>%  #
  arrange(NRO_RADICADO)
#registros_rad_dup


base_unif <- base %>% 
  filter(!(NRO_RADICADO %in% radicados_duplicados))
#246417 observaciones únicas



```
Una vez realizado este proceso, se eliminan 23.386 observaciones, de las que no se pudo recuperar datos.

Luego se procedió a crear/eliminar/modificar, las variables que no se consideran relevantes para el análisis.

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#Eliminar BARRIO, COMUNA, DIRECCION.ENCASILLADA, CBML, NCB, CB, JCB, FECHA_ACCIDENTES....

base2 <- dplyr::select(base_unif,-BARRIO,-COMUNA,-DIRECCION.ENCASILLADA,-CBML,-CB,-JCB,-FECHA_ACCIDENTES,-EXPEDIENTE,-DISEÑO)



```
<div style="text-align: justify">
Se eliminan las variables: 

`BARRIO`,`COMUNA`,`DIRECCION.ENCASILLADA`,`CBML`,`CB`,`JCB`,`FECHA_ACCIDENTES`,`EXPEDIENTE`,`DISEÑO`.  
Algunas de estas variables se encontraban duplicadas.  
* Se quitan tildes    
* Se separar la variable `LOCATION` para obtener las variables `LATITUD` y `LONGITUD`.  
* Se renombran algunas columnas.  
* Se crea la variable `SEMANA`.
<div/>


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
base2$NOMBRE_BAR <- iconv(base2$NOMBRE_BAR, from = "UTF-8", to = "ASCII//TRANSLIT") # Correcion tildes
```



```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
base2 <- separate(base2,LOCATION,c("LONGITUD","LATITUD"),sep=",",convert=TRUE) #SEPARA LONGITUD Y LATITUD DE LOCATION
base2$LONGITUD <- substring(base2$LONGITUD, first = 2) #QUITAR EL ELEMTO "["
base2$LATITUD <- gsub(" ","", base2$LATITUD) #QUITAR EL ESPACIO ANTES DEL NUMERO
base2$LATITUD <- gsub("]","", base2$LATITUD) #QUITAR "]"



```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}


#renombremos las columnas

base2 <- plyr::rename(base2,  c("FECHA_ACCIDENTE"="FECHA","NOMBRE_BAR"="BARRIO","NOMBRE_COM"="COMUNA","GRAVEDAD_ACCIDENTE"="GRAVEDAD","CLASE_ACCIDENTE"="CLASE"))

#colnames(base2)

```


### 2.2. Fechas especiales

Para las fechas especiales se crean dos nuevas variables; `FESTIVIDAD` y `TIPO_FESTIVIDAD`. Estas variables provienen de una base de datos externa que se adiciona a la base de análisis y abarca los días feriados en colombia desde 2014 hasta 2021.

**FESTIVIDAD:** contiene dos etiquetas (SI/NO). SI: cuando hay festividad para ese día. NO: cuando no hay festividad para ese día,  

**TIPO_FESTIVIDAD:** contiene seis tipos de festividad:  
* FESTIVO: día feriado.  
* NAVIDAD: 24,25 y 31 de diciembre.  
* SEM_SANTA: toda la semana santa, desde el lunes hasta el domingo.  
* BRUJAS: 31 de octubre.  
* MADRES: el día d emadres designado para el año respectivo.  
* A_NUEVO: primero de enero de cada año.

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}


# Lectura registros de fechas especiales desde el 2014 a 2021


fechas_especiales <- read.csv("dias_festivos_21.csv", sep = ",", header = T)

class(fechas_especiales$FECHA)

fechas_especiales$FECHA <- as.Date(fechas_especiales$FECHA, format="%d/%m/%Y")#año,mes,dia


class(fechas_especiales$FECHA)



```




```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}

# unir las fechas especiales a base2, los que no son fechas especiales los pone como NA


base2 <- merge(x = base2, y = fechas_especiales, by = "FECHA", all.x = T)
base2$FESTIVIDAD <- ifelse(is.na(base2$FESTIVIDAD),"NO","SI")


base2$FESTIVIDAD <- as.factor(base2$FESTIVIDAD)

summary(base2$FESTIVIDAD)

```


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}


#agregando semana
base2 <- mutate(base2, SEMANA=as.factor(week(base2$FECHA)))

base2$SEMANA <- as.factor(base2$SEMANA)

#(base2$SEMANA)


#Tipo de festividad

fechas_especiales2 <- read.csv("dias_festivos2.csv",
                       sep = ",", 
                       header = T)



#convertir a date
fechas_especiales2$FECHA <- as.Date(fechas_especiales2$FECHA, format="%d/%m/%Y")#año,mes,dia
#base2$FECHA <- as.Date(base2$FECHA)#año,mes,dia



class(base2$FECHA)
class(fechas_especiales2$FECHA)


#pegando el tipo de festividad, se crea una columna que se llama tipo_festividad


base_prueba <- left_join(base2, dplyr::select(fechas_especiales2,FECHA,TIPO_FESTIVIDAD), 
                  by = c("FECHA" = "FECHA"))


base_prueba$TIPO_FESTIVIDAD <- factor(base_prueba$TIPO_FESTIVIDAD, levels = c("A_NUEVO","BRUJAS","FESTIVO","MADRES","NAVIDAD","SEM_SANTA","No_festivo")) 
base_prueba$TIPO_FESTIVIDAD[is.na(base_prueba$TIPO_FESTIVIDAD)] <- "No_festivo"


base_prueba$TIPO_FESTIVIDAD <- as.factor(base_prueba$TIPO_FESTIVIDAD)

summary(base_prueba$TIPO_FESTIVIDAD)



```

Una vez agregada la festividad, la nueva base de datos queda conformada por 246.417 observaciones y 19 variables. 


```{r message=FALSE, warning=FALSE , echo=T}

head(base_prueba, n=6)

base_final <- base_prueba

```

-----------------------------------------------------------------------

## 3. Análisis descriptivo





```{r, message=FALSE, warning=FALSE, include=FALSE}

acc <- base_final %>% group_by(FECHA) %>% 
  dplyr::summarize(numero_de_accidentes = n())
acc$ano <- year(acc$FECHA)
acc$dia <- day(acc$FECHA)
acc$mes <- month(acc$FECHA)
```

### 3.1. Promedio accidentes mensuales por año
```{r message=FALSE, warning=FALSE , echo=T}
aggregate(numero_de_accidentes~ano*mes, data = acc, FUN = mean) %>%
  plot_ly(x = ~mes,
          y = ~numero_de_accidentes, type = "scatter", mode = "lines",
          split = ~ano, line = list(width = 1.5)) %>%
  layout(title = 'Promedio accidentes mensuales mensual por año',
         xaxis = list(title = "Mes"),
         yaxis = list(title = "Número de accidentes"))
```

### 3.2. Registros de accidentalidad diarios 2014-2020
```{r message=FALSE, warning=FALSE , echo=T}

plot_ly(data = acc, x = ~FECHA, y = ~numero_de_accidentes,
        type = "scatter", mode = "lines", split = ~ano,
        line = list(width = 1)) %>%
  layout(title = 'Registros de accidentalidad diarios 2014-2020',
        xaxis = list(title = "Día"),
        yaxis = list(title = "Número de accidentes"))
```

De las gráficas anteriores, se puede observar que:

* Después de febrero el promedio de accidentes en el 2020 disminuyen a gran medida, a tal punto que en mayo solo hay en promedio 26 accidentes.
* El día con menos accidentes es el 23 de mayo del 2020, con solo 9 accidentes.
* El día con más accidentes es el 4 de agosto de 2017, con 213 accidentes.
* En el año 2014 no hay registrados datos de accidentes antes del 4 de julio, lo cual no significa que en estas fechas no ocurrieran accidentes.
-Al igual que en 2014, en el año 2020 no se han registrado accidentes en la base de datos abiertos de Medellín, después del 31 de agosto hasta la fecha actual.



### 3.3. Accidentes por día de la semana
```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
dia_sem <- base %>%
  group_by(DIA_SEMANA) %>%
  summarise(numero_de_accidentes = n())
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
dia_sem$DIA_SEMANA <- ordered(dia_sem$DIA_SEMANA, levels = c("lunes","martes","miercoles","jueves","viernes","sabado","domingo"))
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
gdia <- ggplot(dia_sem, aes(fill = DIA_SEMANA, x = DIA_SEMANA, y = numero_de_accidentes)) +
  geom_bar(stat = "identity") +
  geom_text(aes(y = numero_de_accidentes, label = numero_de_accidentes), vjust = -0.5) +
  xlab("Días") + 
  ylab("Numero de accidentes") + 
  ggtitle("Numero de accidentes por día de la semana") +
  ylim(c(0,40000)) +
  theme(legend.position = "none")
```


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
sem <- base_final %>%
  group_by(SEMANA) %>% 
  summarise(numero_de_ccidentes = n()) %>%
  mutate(SEMANA = as.factor(SEMANA))
```


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
gsem <- ggplot(sem, aes(fill = SEMANA, x = SEMANA, y = numero_de_ccidentes)) +
  geom_bar(stat = "identity") + 
  scale_fill_viridis_d( option = "B") +
  xlab("Semana") +
  ylab("Número de accidentes") +
  ggtitle("Número de accidentes por semana") +
  theme(axis.text.x = element_text(angle = 90, hjust = 0), legend.position = "none")
```

```{r message=FALSE, warning=FALSE , echo=T}
ggarrange(gdia,gsem)
```

El día que presenta mayor cantidad de personas accidentadas, es el  lunes seguido del domingo, con una diferencia de 660 personas. Tras estos dos sigue el martes, mientras que los días miércoles, jueves, viernes y sábado, presentan accidentes más cercamos, con la mayor diferencia entre jueves y sábado de 300 accidentes. El sábado, es el día de la semana con menor cantidad de accidentes.   


### 3.4. Accidentes por mes
```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
mes <- base_final %>%
  group_by(MES) %>%
  summarise(numero_de_accidentes = n()) %>%
  mutate(MES = as.factor(MES))
```

```{r message=FALSE, warning=FALSE , echo=T}
ggplot(data = mes, aes(fill = MES, x = MES, y = numero_de_accidentes)) + 
  geom_bar(stat = "identity") +
  scale_fill_viridis_d( option = "D") +
  geom_text(aes(y = numero_de_accidentes, label = numero_de_accidentes), vjust = -0.5) +
  xlab("Mes") +
  ylab("Número de accidentes") +
  ylim(c(0,26000)) +
  ggtitle("Número de accidentes por mes")+
  theme(legend.position = "none")
```

### 3.5. Accidentes por año
```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
año <- table(base_final$AÑO) %>% 
  as.data.frame()
```

```{r message=FALSE, warning=FALSE , echo=T}
ggplot(data = año, aes(fill = Var1, x = Var1, y = Freq)) +
  geom_bar(stat = "identity") +
  geom_text(aes(y = Freq, label = Freq), vjust = -0.5) +
  scale_fill_viridis_d( option = "H") + 
  xlab("Año") +
  ylab("Número de accidentes") +
  ylim(c(0,45000)) +
  ggtitle("Número de accidentes por año")+
  theme(legend.position = "none")
```


Se debe tener en cuenta, que en los años 2014 y 2020 faltan algunos meses, por ello se presenta una cantidad baja de accidentes, si tener en cuenta ambos años, año con menor cantidad de accidentes es 2018 y 2016 fue el año con más accidentes sólo por unos cientos más que 2015 y 2017.

### 3.6. Festividad
```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
festividad <- base_final %>%
  group_by(FESTIVIDAD) %>%
  summarise(numero_de_accidentes = n())
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
gfes1 <- ggplot(festividad, aes(fill = FESTIVIDAD, x = FESTIVIDAD, y = numero_de_accidentes)) +
  geom_bar(position = "dodge", stat = "identity") +
  geom_text(aes(y = numero_de_accidentes, label = numero_de_accidentes), vjust = -0.5) +
  xlab("festivo") +
  ylab("Número de accidentes") +
  ylim(c(0,240000)) +
  ggtitle("Número de accidentes si son o no festivo")+
  theme(legend.position = "none")
```




```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
tipo_festividad <- base_final %>%
  group_by(TIPO_FESTIVIDAD) %>%
  summarise(numero_de_accidentes = n())
```


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#filtrar los No festivos-->
NO_fes <- tipo_festividad %>%
  filter(TIPO_FESTIVIDAD == "No_festivo")
NO_fes
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
solo_tipo_festividad <- tipo_festividad %>%
  anti_join(NO_fes) 
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
solo_tipo_festividad$TIPO_FESTIVIDAD <- gsub("A_NUEVO","AÑO NUEVO", solo_tipo_festividad$TIPO_FESTIVIDAD)
solo_tipo_festividad$TIPO_FESTIVIDAD <- gsub("MADRES","DIA DE LAS MADRES", solo_tipo_festividad$TIPO_FESTIVIDAD)
solo_tipo_festividad$TIPO_FESTIVIDAD <- gsub("BRUJAS","HALLOWEEN", solo_tipo_festividad$TIPO_FESTIVIDAD)
solo_tipo_festividad$TIPO_FESTIVIDAD <- gsub("SEM_SANTA","SEMANA SANTA", solo_tipo_festividad$TIPO_FESTIVIDAD)
```


```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
gfes2 <- ggplot(solo_tipo_festividad, aes(fill = TIPO_FESTIVIDAD, x = reorder(TIPO_FESTIVIDAD,+numero_de_accidentes), y = numero_de_accidentes)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d( option = "D") +
  geom_text(aes(y = numero_de_accidentes, label = numero_de_accidentes), vjust = -0.5) +
  xlab("festividad") +
  ylab("Número de accidentes") +
  ylim(c(0,5000)) +
  ggtitle("Número de accidentes en las festividades") +
  theme(axis.text.x = element_text(angle = 90, hjust = 0), legend.position = "none")
```

```{r message=FALSE, warning=FALSE , echo=T}
ggarrange(gfes1,gfes2)
```



### 3.7. Acidentes por comuna
```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
acc_comuna <- base_final %>%
  group_by(COMUNA) %>% 
  dplyr::summarize(accidentes = n())
acc_comuna
```


```{r message=FALSE, warning=FALSE , echo=T}
ggplot(data = acc_comuna, aes( fill = COMUNA, x = reorder(COMUNA,+accidentes), y = accidentes)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d( option = "B") +
  geom_text(aes(y = accidentes, label = accidentes), hjust = -0.1) +
  xlab("Comuna") + 
  ylab("Total accidentes") +
  ggtitle("Total accidentes por comuna 2014-2018") +
  ylim(c(0,60000)) +
  coord_flip() +
  theme(legend.position = "none")
```
  
  
  
Se puede apreciar en la gráfica, que la mayor cantidad de accidentes ocurren en La Candelaria, incluso la cantidad de accidentes casi que duplica los accidentes en Laureles, que es la comuna que le sigue en cantidad de accidentes. Por otro lado, la comuna con menor cantidad de accidentes es Palmitas.


### 3.8. Número de accidentes por su gravedad
```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
gravedad <- base_final %>%
  group_by(GRAVEDAD) %>%
  summarise(numero_de_accidentes = n())
```

```{r message=FALSE, warning=FALSE , echo=T}
ggplot(data = gravedad, aes(fill = GRAVEDAD, x = GRAVEDAD, y = numero_de_accidentes)) +
  geom_bar(stat = "identity") + 
  scale_fill_manual(values = c("green", "red", "blue")) +
  geom_text(aes(y = numero_de_accidentes, label = numero_de_accidentes), vjust = -0.5) +
  xlab("Gravedad") + 
  ylab("Número de acccidentes") + 
  ggtitle("Total Accidentes por gravedad") +
  ylim(c(0,150000))+
  theme(legend.position = "none")
  
```
  


De los accidentes registrados de 2014 a 2020, visualizando la gravedad en esta gráfica podemos apreciar que la cantidad de muertos respecto a la cantidad de accidentes total es poca, y con heridos en la mayoria de accidentes aunque hablemos de muertes, es un alivio que en la mayor parte de los accidentes sólo sean daños o personas heridas.

-------------------------------------------------------------------



## 4. Entrenamiento de un modelo predictivo


En la etapa de entrenamiento del modelo predictivo, se utilizó el registro histórico de accidentes desde el año 2014 hasta el año 2017, y para la etapa de validación se hizo uso de los registros de los años 2018 y 2019. Ésto debido a las especificaciones del trabajo para predecir la accidentalidad en Medellín.

### 4.1. Modelo Lineal

Inicialmente se utiliza un modelo lineal con las variables `Festividad`, `Día Semana` y `Diseño`.

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F }

base_final <- read.csv("base_final2.csv", encoding="UTF-8")
#Modelo lineal


base_final$CLASE <- as.factor(as.character(base_final$CLASE))
datos_vl <- subset(base_final, (AÑO == '2018'))
base_final01 <- subset(base_final, (AÑO != '2018'))
base_final02 <- subset(base_final01, (AÑO != '2019'))
base_final03 <- subset(base_final02, (AÑO != '2020'))

datos_lm1 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   DISENO) %>% dplyr::count(name = "NRO_ACCID") 
lm1 <- lm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA+DISENO, data = datos_lm1)
promedio <- mean(datos_lm1$NRO_ACCID)
TSS <- sum((datos_lm1$NRO_ACCID - promedio)^2)
RSS <- RSS(lm1)
r2 <- 1-RSS/TSS
RSS2 <- anova(lm1)[4, 2]
r2 <- 1-RSS/TSS
```

En este modelo se va a observar el **MSE** (Error Cuadrático Medio) y el **$R^2$** (Coeficiente de Determinación) para determinar la potencia del modelo para predecir.

#### 4.1.1. Predicción y Evaluación para los datos de Entrenamiento

```{r message=FALSE, warning=FALSE , echo=T }
lm1_data <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   DISENO) %>% dplyr::count(name = "NRO_ACCID") 
lm1_tr <- lm1_data[,-c(5)]

predicted <- round(predict(lm1, newdata=lm1_tr))
actual <- lm1_data$NRO_ACCID

lm1_mse <- MSE(predicted, actual) # MSE
lm1_mae <- MAE(predicted, actual) # MAE
lm1_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm1_mse, lm1_mae, lm1_r2)

```
#### 4.1.2. Predicción y Evaluación para los datos de Validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T }

lm1_2018 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                  DISENO) %>% dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm1, newdata=lm1_2018))
actual <- lm1_2018$NRO_ACCID

lm1_mse <- MSE(predicted, actual) # MSE
lm1_mae <- MAE(predicted, actual) # MAE
lm1_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm1_mse, lm1_mae, lm1_r2)

```
La diferencia del MSE entre los datos de entrenamiento y validación del 2018 es del 34.48%, que al ser mayor que el 15% indica un posible sobreajuste. Además se puede apreciar que el $R^2$ de los datos de validación para el año 2018 predice un 72.86%, sin embargo disminuyó un 16.82% en cuanto al $R^2$ para los datos de entrenamiento. Así que luego de ésto se decide igualmente ver qué sucede con el mismo modelo validando con el año 2019.

#### 4.1.3. Predicción y Evaluación para los datos de Validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T }

datos_vl02 <- subset(base_final, (AÑO == '2019'))

lm1_2019 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                  DISENO) %>% dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm1, newdata=lm1_2019))
actual <- lm1_2019$NRO_ACCID

lm1_mse <- MSE(predicted, actual) # MSE
lm1_mae <- MAE(predicted, actual) # MAE
lm1_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm1_mse, lm1_mae, lm1_r2)

```

La diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 41.29%, que al ser mayor que el 15% indica un posible sobreajuste. Además se puede evidenciar que el $R^2$ de los datos de validación para el año 2019 predice un 76.53%, sin embargo aunque mejoró con respecto a la validación del año 2018, disminuyó un 13.15% en cuanto al $R^2$ para los datos de entrenamiento. Por tanto, al obtener estos resultados validando con los años 2018 y 2019 se decide buscar un nuevo modelo cambiando las variables.

### 4.2. Modelo Lineal con disminución de Variables

Para este nuevo modelo se decide utilizar un modelo lineal únicamente con las variables "Festividad" y "Día Semana". Es decir, se omite en este caso "Diseño" para observar qué cambios pueden ocurrir en el modelo.

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F }
datos_lm2 <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

lm2 <- lm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA, data = datos_lm2)

```

#### 4.2.1. Predicción y Evaluación para los datos de Entrenamiento

```{r message=FALSE, warning=FALSE , echo=T }
lm2_tr <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm2, newdata=lm2_tr))
actual <- lm2_tr$NRO_ACCID

lm2_mse <- MSE(predicted, actual) # MSE
lm2_mae <- MAE(predicted, actual) # MAE
lm2_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm2_mse, lm2_mae, lm2_r2)
```
#### 4.2.2. Predicción y Evaluación para los datos de Validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T }
lm2_2018 <- datos_vl %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm2, newdata=lm2_2018))
actual <- lm2_2018$NRO_ACCID

lm2_mse <- MSE(predicted, actual) # MSE
lm2_mae <- MAE(predicted, actual) # MAE
lm2_r2 <- R2_Score(predicted, actual) # R2


sprintf("MSE: %f, MAE: %f, R2: %f", lm2_mse, lm2_mae, lm2_r2)
```
Con este nuevo modelo disminuyendo variables no se obtuvieron resultados positivos, ya que el R2 disminuyó notablemente tanto en el entrenamiento, como en la validación con el año 2018 y la diferencia entre el MSE de datos de entrenamiento y validación para el año 2018 fue de 57.89%, lo cual indica que aumentó, indicando así una alta variabilidad en cuanto a las predicciones y de esa forma, una baja variabilidad explicada por este nuevo modelo.

#### 4.2.3. Predicción y Evaluación para los datos de Validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T }

lm2_2019 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm2, newdata=lm2_2019))
actual <- lm2_2019$NRO_ACCID

lm2_mse <- MSE(predicted, actual) # MSE
lm2_mae <- MAE(predicted, actual) # MAE
lm2_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm2_mse, lm2_mae, lm2_r2)

```

Para este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 91.02%, que claramente indica un sobreajuste. Y se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 10.07%. Así que se concluye que este modelo no sirve para predecir según los resultados obtenidos tanto en el entrenamiento, como para la validación en los años de 2018 y 2019. Así que se decide utilizar un modelo lineal generalizado.

### 4.3. Modelo Lineal Generalizado

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F  }
datos_lm3 <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

lm3 <- glm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA, family = "poisson", data = datos_lm3) # Modelo lineal generalizado, con familia poisson

```

#### 4.3.1. Predicción y Evaluación para los datos de Entrenamiento

```{r message=FALSE, warning=FALSE , echo=T }
lm3_tr <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

lm3_tr_1 <- lm3_tr[,-4]

predicted <- round(predict(lm3, newdata=lm3_tr_1, type="response"))
actual <- lm3_tr$NRO_ACCID

lm3_mse <- MSE(predicted, actual) # MSE
lm3_mae <- MAE(predicted, actual) # MAE
lm3_r2 <- R2_Score(predicted, actual)

sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm3_mse, lm3_mae, lm3_r2)
```

#### 4.3.2. Predicción y Evaluación para los datos de Validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T }
lm3_2018 <- datos_vl %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm3, newdata=lm3_2018, type="response")) 
actual <- lm3_2018$NRO_ACCID

lm3_mse <- MSE(predicted, actual) # MSE
lm3_mae <- MAE(predicted, actual) # MAE
lm3_r2 <- R2_Score(predicted, actual)

sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm3_mse, lm3_mae, lm3_r2)
```

En este modelo lineal generalizado con la familia de distribución Poisson se obtuvo un $R^2$ en la etapa de entrenamiento de 7.21%, y para la etapa de validación para el año 2018 el $R^2$ fue de 2.88%,lo cual indica que dicho modelo no sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 57.89%, que indica un sobreajuste. Sin embargo se procede a validar igualmente con el año 2019.

#### 4.3.3. Predicción y Evaluación para los datos de Validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T }
lm3_2019 <- datos_vl02 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  dplyr::count(name = "NRO_ACCID")

predicted <- round(predict(lm3, newdata=lm3_2019, type="response")) 
actual <- lm3_2019$NRO_ACCID

lm3_mse <- MSE(predicted, actual) # MSE
lm3_mae <- MAE(predicted, actual) # MAE
lm3_r2 <- R2_Score(predicted, actual)

sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm3_mse, lm3_mae, lm3_r2)
```

Para este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 90.91%, que claramente indica un sobreajuste. Y se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 10.1%. Así que se evidencia que este modelo no sirve para predecir según los resultados obtenidos tanto en el entrenamiento, como para la validación en los años de 2018 y 2019. Así que se decide utilizar el modelo lineal generalizado adicinando otra variable.

### 4.4. Modelo lineal generalizado con Adición de la variable Clase

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F }
datos_lm4 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   CLASE) %>% dplyr::count(name = "NRO_ACCID")

lm4 <- glm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA+CLASE, family = "poisson", 
           data = datos_lm4)
```

#### 4.4.1. Predicción y Evaluación para los datos de Entrenamiento

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm4_p <- datos_lm4[,-5]
y_train <- round(predict(lm4, newdata= datos_lm4_p, type="response"))
y_actual <- datos_lm4$NRO_ACCID
lm4_tmse <- MSE(y_train, y_actual)
lm4_tmae <-  MAE(y_train, y_actual)
lm4_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm4_tmse, lm4_tmae, lm4_r2)
```

#### 4.4.2. Predicción y Evaluación para los datos de Validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm4_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE) %>% dplyr::count(name = "NRO_ACCID")
datos_lm4_v2 <- datos_lm4_v1[,-5]

y_train <- round(predict(lm4, newdata= datos_lm4_v2, type="response"))
y_actual <- datos_lm4_v1$NRO_ACCID
lm4_tmse <- MSE(y_train, y_actual)
lm4_tmae <-  MAE(y_train, y_actual)
lm4_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm4_tmse, lm4_tmae, lm4_r2)

```

En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Clase se obtuvo un $R^2$ en la etapa de entrenamiento de 88.6%,y para la etapa de validación para el año 2018 el $R^2$ fue de 89.51%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 10.03%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Luego se procede a validar con el año 2019. 

#### 4.4.3. Predicción y Evaluación para los datos de Validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm4_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE) %>% dplyr::count(name = "NRO_ACCID")
datos_lm4_v2 <- datos_lm4_v1[,-5]

y_train <- round(predict(lm4, newdata= datos_lm4_v2, type="response"))
y_actual <- datos_lm4_v1$NRO_ACCID
lm4_tmse <- MSE(y_train, y_actual)
lm4_tmae <-  MAE(y_train, y_actual)
lm4_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm4_tmse, lm4_tmae, lm4_r2)

```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 0.94%, que fue menor al valor obtenido con la validación del 2018 (10.03%), que indica claramente que no hay problemas de sobreentrenamiento. Además se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 88.63%, evidenciando así que este modelo lineal generalizado con la adición de la variable Clase es un buen candidato para predecir la accidentalidad en Medellín. Sin embargo, se adicionará otra variable para ver si se obtiene un mejor modelo.

### 4.5. Modelo lineal generalizado con Adición de la variable Diseño

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F }

datos_lm5 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   CLASE, DISENO) %>% dplyr::count(name = "NRO_ACCID")

lm5 <- glm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA+CLASE+DISENO, family = "poisson", 
           data = datos_lm5)
```

#### 4.5.1. Predicción y Evaluación para los datos de Entrenamiento

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm5_p <- datos_lm5[,-6]
y_train <- round(predict(lm5, newdata= datos_lm5_p, type="response"))
y_actual <- datos_lm5$NRO_ACCID
lm5_tmse01 <- MSE(y_train, y_actual)
lm5_tmae <-  MAE(y_train, y_actual)
lm5_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm5_tmse01, lm5_tmae, lm5_r2)
```
#### 4.5.2. Predicción y Evaluación para los datos de Validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm5_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE, DISENO) %>% dplyr::count(name = "NRO_ACCID")
datos_lm5_v2 <- datos_lm5_v1[,-6]

y_train <- round(predict(lm5, newdata= datos_lm5_v2, type="response"))
y_actual <- datos_lm5_v1$NRO_ACCID
lm5_tmse02 <- MSE(y_train, y_actual)
lm5_tmae <-  MAE(y_train, y_actual)
lm5_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm5_tmse02, lm5_tmae, lm5_r2)
```
En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Diseño se obtuvo un $R^2$ en la etapa de entrenamiento de 86.56%, y para la etapa de validación para el año 2018 el $R^2$ fue de 81.93%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. La diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 4.92%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Así, se procede a validar con el año 2019. 

#### 4.5.3. Predicción y Evaluación para los datos de Validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm5_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE, DISENO) %>% dplyr::count(name = "NRO_ACCID")
datos_lm5_v2 <- datos_lm5_v1[,-6]

y_train <- round(predict(lm5, newdata= datos_lm5_v2, type="response"))
y_actual <- datos_lm5_v1$NRO_ACCID
lm5_tmse02 <- MSE(y_train, y_actual)
lm5_tmae <-  MAE(y_train, y_actual)
lm5_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm5_tmse02, lm5_tmae, lm5_r2)
```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 3.4%, que indica que no hay problemas de sobreentrenamiento. También se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 82.91%, que evidencia que este modelo lineal generalizado con la adición de la variable Diseño es buen candidato para predecir la accidentalidad en Medellín.

Este modelo presenta el mejor MSE, pero no es un modelo viable ya que no es posible obtener la variable DISENO para realizar predicciones, según las pautas dadas.

Finalmente, se decide trabajar con el modelo lineal generalizado que posee la variable CLASE, ya que como se analizó anteriormente, se observa que tanto para los datos de entrenamiento, como para los de validación (2018, 2019) se pueden obtener buenas predicciones.

Luego, con el modelo elegido se procedió a realizar la etapa de entrenamiento y validación de forma semanal y mensual ya que dicho modelo para la predicción diaria tuvo buenos resultados, tanto para el MSE, como para el $R^2$, para así observar si también con dicho modelo se pueden obtener buenas predicciones no solamente de manera diaria.

### 4.6. Semanal

#### 4.6.1. Modelo lineal generalizado con adición de la variable Clase

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F }
datos_lm6 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, SEMANA, 
                                   CLASE) %>% dplyr::count(name = "NRO_ACCID")

lm6 <- glm(NRO_ACCID ~ FESTIVIDAD+SEMANA+CLASE, family = "poisson", 
           data = datos_lm6)
```

#### 4.6.2. Predicción y evaluación para los datos de entrenamiento

```{r message=FALSE, warning=FALSE , echo=T}
datos_lm6_p <- datos_lm6[,-5]
y_train <- round(predict(lm6, newdata= datos_lm6_p, type="response"))
y_actual <- datos_lm6$NRO_ACCID
lm6_tmse <- MSE(y_train, y_actual)
lm6_tmae <-  MAE(y_train, y_actual)
lm6_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm6_tmse, lm6_tmae, lm6_r2)
```

#### 4.6.3. Predicción y Evaluación para los datos de Validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T}
datos_lm6_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, SEMANA, 
                                      CLASE) %>% dplyr::count(name = "NRO_ACCID")
datos_lm6_v2 <- datos_lm6_v1[,-5]

y_train <- round(predict(lm6, newdata= datos_lm6_v2, type="response"))
y_actual <- datos_lm6_v1$NRO_ACCID
lm6_tmse <- MSE(y_train, y_actual)
lm6_tmae <-  MAE(y_train, y_actual)
lm6_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm6_tmse, lm6_tmae, lm6_r2)

```

En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Clase se obtuvo un $R^2$ en la etapa de entrenamiento de 88.84%,y para la etapa de validación para el año 2018 el $R^2$ fue de 89.65%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 9.15%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Luego se procede a validar con el año 2019. 

#### 4.6.4. Predicción y Evaluación para los datos de Validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T }
datos_lm6_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, SEMANA, 
                                      CLASE) %>% dplyr::count(name = "NRO_ACCID")
datos_lm6_v2 <- datos_lm6_v1[,-5]

y_train <- round(predict(lm6, newdata= datos_lm6_v2, type="response"))
y_actual <- datos_lm6_v1$NRO_ACCID
lm6_tmse <- MSE(y_train, y_actual)
lm6_tmae <-  MAE(y_train, y_actual)
lm6_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm6_tmse, lm6_tmae, lm6_r2)

```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del  1.27%, que fue menor al valor obtenido con la validación del 2018 (9.15%), que indica claramente que no hay problemas de sobreentrenamiento. Además se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 88.83%, evidenciando así que este modelo lineal generalizado con la adición de la variable Clase es un buen candidato para predecir la accidentalidad en Medellín.


### 4.7. Mensual

#### 4.7.1. Modelo lineal generalizado con adición de la variable Clase

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
datos_lm7 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, MES, 
                                   CLASE) %>% dplyr::count(name = "NRO_ACCID")

lm7 <- glm(NRO_ACCID ~ FESTIVIDAD+MES+CLASE, family = "poisson", 
           data = datos_lm7)
```

#### 4.7.2. Predicción y evaluación para los datos de entrenamiento

```{r message=FALSE, warning=FALSE , echo=T}
datos_lm7_p <- datos_lm7[,-5]
y_train <- round(predict(lm7, newdata= datos_lm7_p, type="response"))
y_actual <- datos_lm7$NRO_ACCID
lm7_tmse <- MSE(y_train, y_actual)
lm7_tmae <-  MAE(y_train, y_actual)
lm7_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm7_tmse, lm7_tmae, lm7_r2)
```

#### 4.7.3. Predicción y evaluación para los datos de validación en el año 2018

```{r message=FALSE, warning=FALSE , echo=T}
datos_lm7_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, MES, 
                                      CLASE) %>% dplyr::count(name = "NRO_ACCID")
datos_lm7_v2 <- datos_lm7_v1[,-5]

y_train <- round(predict(lm7, newdata= datos_lm7_v2, type="response"))
y_actual <- datos_lm7_v1$NRO_ACCID
lm7_tmse <- MSE(y_train, y_actual)
lm7_tmae <-  MAE(y_train, y_actual)
lm7_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm7_tmse, lm7_tmae, lm7_r2)

```

En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Clase se obtuvo un $R^2$ en la etapa de entrenamiento de 88.84%,y para la etapa de validación para el año 2018 el $R^2$ fue de 88.81%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 2.19%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Luego se procede a validar con el año 2019. 

#### 4.7.4. Predicción y evaluación para los datos de validación en el año 2019

```{r message=FALSE, warning=FALSE , echo=T}
datos_lm7_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, MES, 
                                      CLASE) %>% dplyr::count(name = "NRO_ACCID")
datos_lm7_v2 <- datos_lm7_v1[,-5]

y_train <- round(predict(lm7, newdata= datos_lm7_v2, type="response"))
y_actual <- datos_lm7_v1$NRO_ACCID
lm7_tmse <- MSE(y_train, y_actual)
lm7_tmae <-  MAE(y_train, y_actual)
lm7_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm7_tmse, lm7_tmae, lm7_r2)

```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del  1.3%, que fue menor al valor obtenido con la validación del 2018 (2.19%), que indica claramente que no hay problemas de sobreentrenamiento. Además se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 88.83%, evidenciando así que este modelo lineal generalizado con la adición de la variable Clase es un buen candidato para predecir la accidentalidad en Medellín.

### 4.8. Predicciones

#### 4.8.1. Predicción diaria del 2020

Se presenta una tabla con el encabezado de las primeras 10 observaciones para las predicciones diarias obtenidas para el año 2020:

```{r message=FALSE, warning=FALSE , echo=T}
Base_prediccion <- read.csv("prediccion.csv", sep = ",", encoding = "UTF-8")

Base_prediccion <- Base_prediccion[,-1]

Base_prediccion_2020 <- subset(Base_prediccion, (AÑO != '2021'))

Base_prediccion_2020$FECHA <- as.Date(Base_prediccion_2020$FECHA)
Base_prediccion_2020$CLASE <- as.factor(Base_prediccion_2020$CLASE)
Base_prediccion_2020$DIA_SEMANA <- as.factor(Base_prediccion_2020$DIA_SEMANA)
Base_prediccion_2020$AÑO <- as.integer(Base_prediccion_2020$AÑO)
Base_prediccion_2020$FESTIVIDAD <- as.factor(Base_prediccion_2020$FESTIVIDAD)

prediccion_2020 <- predict(object = lm4, newdata = Base_prediccion_2020,
                          type = "response")
prediccion_diaria2020 <- Base_prediccion_2020 %>% 
  mutate(NRO_ACCID = round(prediccion_2020,0))

diario_20_02 <- prediccion_diaria2020 %>%
  group_by(FECHA, DIA_SEMANA, CLASE, FESTIVIDAD) %>%
  dplyr::summarise(NRO_TOTAL_ACCID=NRO_ACCID)

head(diario_20_02, 10)

```

#### 4.8.2. Predicción diaria del 2021

A continuación, se presenta una tabla con el encabezado de las primeras 10 observaciones para las predicciones diarias obtenidas para el año 2021:

```{r message=FALSE, warning=FALSE , echo=T}
Base_prediccion_2021 <- subset(Base_prediccion, (AÑO != '2020'))

Base_prediccion_2021$FECHA <- as.Date(Base_prediccion_2021$FECHA)
Base_prediccion_2021$CLASE <- as.factor(Base_prediccion_2021$CLASE)
Base_prediccion_2021$DIA_SEMANA <- as.factor(Base_prediccion_2021$DIA_SEMANA)
Base_prediccion_2021$AÑO <- as.integer(Base_prediccion_2021$AÑO)
Base_prediccion_2021$FESTIVIDAD <- as.factor(Base_prediccion_2021$FESTIVIDAD)

prediccion_2021 <- predict(object = lm4, newdata = Base_prediccion_2021,
                          type = "response")
prediccion_diaria2021 <- Base_prediccion_2021 %>% 
  mutate(NRO_ACCID = round(prediccion_2021,0))

diario_21_02 <- prediccion_diaria2021 %>%
  group_by(FECHA, DIA_SEMANA, CLASE, FESTIVIDAD) %>%
  dplyr::summarise(NRO_TOTAL_ACCID=NRO_ACCID)

head(diario_21_02, 10)

```

#### 4.8.3. Predicción semanal del 2020

De igual forma, se presenta una tabla con el encabezado de las primeras 10 observaciones para las predicciones semanales que se obtuvieron para el año 2020:

```{r message=FALSE, warning=FALSE , echo=T}

Base_prediccion03 <- Base_prediccion[,-4]
Base_prediccion04 <- Base_prediccion03[,-4]

Base_prediccion_2020 <- subset(Base_prediccion, (AÑO != '2021'))

Base_prediccion_2020 <- subset(Base_prediccion04, (AÑO != '2021'))


Base_prediccion_2020$SEMANA <- as.integer(Base_prediccion_2020$SEMANA)


prediccion_2020_02 <- predict(object = lm6, newdata = Base_prediccion_2020,
                          type = "response")
prediccion_semanal2020 <- Base_prediccion_2020 %>% 
  mutate(NRO_ACCID = round(prediccion_2020_02,0))

semanal <- prediccion_semanal2020 %>% group_by(CLASE, SEMANA = week(FECHA), NRO_ACCID, FESTIVIDAD) %>% dplyr::summarize(total = n())
semanal <- mutate(semanal, NRO_ACCID_TOTAL=NRO_ACCID*total)

semanal_20_02 <- semanal %>%
  group_by(SEMANA, CLASE, FESTIVIDAD) %>%
  dplyr::summarise(NRO_TOTAL_ACCID=sum(NRO_ACCID_TOTAL))

head(semanal_20_02, 10)
```

#### 4.8.4. Predicción semanal del 2021

También, acá se puede observar una tabla con el encabezado de las primeras 10 observaciones para las predicciones semanales que se obtuvieron para el año 2021:

```{r message=FALSE, warning=FALSE , echo=T}
base_final03 <- subset(base_final02, (AÑO != '2020'))
Base_prediccion_2021 <- subset(Base_prediccion, (AÑO != '2020'))

Base_prediccion_2021$FECHA <- as.Date(Base_prediccion_2021$FECHA)
Base_prediccion_2021$CLASE <- as.factor(Base_prediccion_2021$CLASE)
Base_prediccion_2021$DIA_SEMANA <- as.factor(Base_prediccion_2021$DIA_SEMANA)
Base_prediccion_2021$AÑO <- as.integer(Base_prediccion_2021$AÑO)
Base_prediccion_2021$FESTIVIDAD <- as.factor(Base_prediccion_2021$FESTIVIDAD)

prediccion_2021 <- predict(object = lm4, newdata = Base_prediccion_2021,
                          type = "response")
prediccion_semanal2021 <- Base_prediccion_2021 %>% 
  mutate(NRO_ACCID = round(prediccion_2021,0))

#borrando columnas no necesarias
prediccion_semanal2021 <-  prediccion_semanal2021[,c(-1,-2,-4,-5)]

#Se agrupó por semana 2021
semanal_21 <- prediccion_semanal2021 %>% group_by(CLASE, SEMANA, NRO_ACCID, FESTIVIDAD) %>% dplyr::summarize(total = n())
semanal_21 <- mutate(semanal_21, NRO_ACCID_TOTAL=NRO_ACCID*total)

semanal_21_02 <- semanal_21 %>%
  group_by(SEMANA, CLASE, FESTIVIDAD) %>%
  dplyr::summarise(NRO_TOTAL_ACCID=sum(NRO_ACCID_TOTAL))

head(semanal_21_02, 10)
```

#### 4.8.5. Predicción mensual del 2020

De manera resumida, se presenta una tabla con el encabezado de las primeras 10 observaciones para las predicciones mensuales que se obtuvieron para el año 2020:

```{r message=FALSE, warning=FALSE , echo=T}
Base_prediccion <- read.csv("prediccion.csv", sep = ",", encoding = "UTF-8")

Base_prediccion_2020 <- subset(Base_prediccion, (AÑO != '2021'))

Base_prediccion_2020$FECHA <- as.Date(Base_prediccion_2020$FECHA)
Base_prediccion_2020$CLASE <- as.factor(Base_prediccion_2020$CLASE)
Base_prediccion_2020$DIA_SEMANA <- as.factor(Base_prediccion_2020$DIA_SEMANA)
Base_prediccion_2020$AÑO <- as.integer(Base_prediccion_2020$AÑO)
Base_prediccion_2020$FESTIVIDAD <- as.factor(Base_prediccion_2020$FESTIVIDAD)

prediccion_2020 <- predict(object = lm4, newdata = Base_prediccion_2020,
                          type = "response")
prediccion_mensual2020 <- Base_prediccion_2020 %>% 
  mutate(NRO_ACCID = round(prediccion_2020,0))

#Se borraron columnas no necesarias
prediccion_mensual2020 <-  prediccion_mensual2020[,c(-1,-2,-3,-5,-7)]

#Agrupamiento por mes 2020

#Se agrupó por mes y si fue en día festivo o no
mensual_20 <- prediccion_mensual2020 %>% group_by(CLASE, MES, NRO_ACCID, FESTIVIDAD) %>% dplyr::summarize(total = n())
mensual_20 <- mutate(mensual_20, NRO_ACCID_TOTAL=NRO_ACCID*total)

mensual_20_02 <- mensual_20 %>%
  group_by(MES, CLASE, FESTIVIDAD) %>%
  dplyr::summarise(NRO_TOTAL_ACCID=sum(NRO_ACCID_TOTAL))

head(mensual_20_02, 10)
```

#### 4.8.6. Predicción mensual del 2021

Igualmente, se presenta una tabla con el encabezado de las primeras 10 observaciones para las predicciones mensuales que se obtuvieron para el año 2021:

```{r message=FALSE, warning=FALSE , echo=T}
Base_prediccion_2021 <- subset(Base_prediccion, (AÑO != '2020'))

Base_prediccion_2021$FECHA <- as.Date(Base_prediccion_2021$FECHA)
Base_prediccion_2021$CLASE <- as.factor(Base_prediccion_2021$CLASE)
Base_prediccion_2021$DIA_SEMANA <- as.factor(Base_prediccion_2021$DIA_SEMANA)
Base_prediccion_2021$AÑO <- as.integer(Base_prediccion_2021$AÑO)
Base_prediccion_2021$FESTIVIDAD <- as.factor(Base_prediccion_2021$FESTIVIDAD)

prediccion_2021 <- predict(object = lm4, newdata = Base_prediccion_2021,
                          type = "response")
prediccion_mensual2021 <- Base_prediccion_2021 %>% 
  mutate(NRO_ACCID = round(prediccion_2021,0))

#Se borranron columnas no necesarias
prediccion_mensual2021 <-  prediccion_mensual2021[,c(-1,-2,-3,-5,-7)]

#Agrupamiento por mes 2021

#Se agrupó por mes y si fue en día festivo o no
mensual_21 <- prediccion_mensual2021 %>% group_by(CLASE, MES, NRO_ACCID, FESTIVIDAD) %>% dplyr::summarize(total = n())
mensual_21 <- mutate(mensual_21, NRO_ACCID_TOTAL=NRO_ACCID*total)

mensual_21_02 <- mensual_21 %>%
  group_by(MES, CLASE, FESTIVIDAD) %>%
  dplyr::summarise(NRO_TOTAL_ACCID=sum(NRO_ACCID_TOTAL))

head(mensual_21_02, 10)
```

------------------------------------------------------------------


## 5. Agrupamiento de los barrios de Medellín de acuerdo a su accidentalidad

Antes de realizar la agrupación de barrios según la accidentalidad se decide mostrar primero un mapa de calor de accidentalidad en la ciudad de Medellín entre los años de 2014 y 2019, ya que este mapa a su vez representaría la historia de la accidentalidad. Lo anterior, teniendo presente que para este proyecto se pretende predecir para los años de 2020 y 2021.

### 5.1. Mapa de accidentes en la ciudad de Medellín

Para la elaboración del mapa calor según la accidentalidad, se descargó un archivo .shp del Límite Barrio Vereda Catastral

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#lectura de .csv y .shp
catastral <- read.csv("Limite_Barrio_Vereda_Catastral.csv", encoding="UTF-8")

catastro <- read_sf("Limite_Barrio_Vereda_Catastral.shp")

barrio_vereda <- read.csv("Barrio_Vereda_2014.csv", encoding="UTF-8")

```

```{r message=FALSE, warning=FALSE , echo=T}
#Mapa para todos los barrios, usando 'innerjoin' con el .shp de Limite_Barrio_Vereda_Catastral

Unido <- inner_join(catastral, base_final, by = c("COMUNA" = "NUMCOMUNA"))

nueva_base <- Unido %>% filter(AÑO >= 2014 & AÑO <= 2019) %>% 
  group_by(CODIGO) %>%
  dplyr::summarise(accidentes = n()) %>%
  ungroup()

#Se realizó la conversión de CODIGO a formato numérico

catastro$CODIGO <- as.numeric(as.character(catastro$CODIGO))

#Se utilizó 'inner join' para unir dos bases y para luego generar mapa

mapa <- inner_join(catastro, nueva_base, by = c("CODIGO" = "CODIGO"))

mypal <- colorNumeric(palette = c("#000000","#280100","#3D0201","#630201","#890100","#B00100","#DD0100","#F50201",
                                   "#FF5F5E","#FF7A79","#FF9796","#FEB1B0","#FDC9C8", "#FFE5E4"), domain = mapa$accidentes, reverse = T)

# Creación del mapa

leaflet() %>% addPolygons(data = mapa, color = "#0A0A0A", opacity = 0.6, weight = 1, fillColor = ~mypal(mapa$accidentes),
                          fillOpacity = 0.6, label = ~NOMBRE_BAR,
                          highlightOptions = highlightOptions(color = "black", weight = 3, bringToFront = T, opacity = 1),
                          popup = paste("Barrio: ", mapa$NOMBRE_BAR, "<br>", "Accidentes: ", mapa$accidentes, "<br>")) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addLegend(position = "bottomright", pal = mypal, values = mapa$accidentes, title = "Accidentes", opacity = 0.6)
```

```{r message=FALSE, warning=FALSE , echo=T}
# Cantidad de Accidentes por Comuna

medellin_comuna <- base_final %>% filter(AÑO >= 2014 & AÑO <= 2019) %>% 
  group_by(COMUNA) %>% 
  dplyr::summarize(accidentes = n())

ggplot(data = medellin_comuna, aes(x = reorder(COMUNA,+accidentes), y = accidentes)) +
  geom_bar(stat = "identity", position = "dodge", fill = "blue", color = "black", alpha = 0.6) +
  geom_text(aes(y = accidentes, label = accidentes),
                position = position_dodge(width = 0.7), size = 3.5, vjust = 0.5, hjust = -0.1, col = "black") +
  xlab("Comuna") + 
  ylab("Total de Accidentes") +
  ggtitle("Total de Accidentes por Comuna entre los años 2014 y 2019") +
  ylim(c(0,50000)) +
  theme_minimal() +
  coord_flip()
```

Al analizar la accidentalidad por Barrio y Comuna, tanto en el mapa de accidentalidad como en el gráfico, se observó que La Candelaria es el lugar donde más se presentan accidentes entre los años 2014 y 2019, seguida por Laureles y Castilla. También, se evidencia que Palmitas es el lugar donde ocurre menos accidentalidad en Medellín durante los años 2014-2019. Además en el mapa de calor se puede notar que la zona centro y las vías principales son las más afectadas por los accidentes.

Luego se procede a crear una función para calular distancias para datos geoespaciales y además se crea un dendograma para así emprender la búsqueda del $K$ óptimo para el agrupamiento (tomando los datos de 2014 hasta 2017, ya que éstos fueron los años que se utilizaron para el modelo de predicción).

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#Haciendo uso de la librería 'geosphere', se creó una función para calcular las distancias para datos geoespaciales

geo.dist = function(df) {
  require(geosphere)
  d <- function(i,z){         # z[1:2] contain long, lat
    dist <- rep(0,nrow(z))
    dist[i:nrow(z)] <- distHaversine(z[i:nrow(z),1:2],z[i,1:2])
    return(dist)
  }
  dm <- do.call(cbind,lapply(1:nrow(df),d,df))
  return(as.dist(dm))
}
```

```{r }
#Se realizó la conversión de la latitud y longitud al formato numérico

base_final03$LATITUD <- as.numeric(as.character(base_final03$LATITUD))
base_final03$LONGITUD<- as.numeric(as.character(base_final03$LONGITUD))
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#Se creó un nuevo dataset para el agrupamiento, según longitud, latitud y barrio almacenado en 'df'
df <- data.frame(long = base_final03$LONGITUD, lat = base_final03$LATITUD, barrios = base_final03$BARRIO)
```

```{r message=FALSE, warning=FALSE , echo=T}
#Se creó con la función 'geo.dist', una matriz de distancias
df1 <- df[1:1000, ]
d <- geo.dist(df1)
hc <- hclust(d)
plot(hc, main = "Dendograma", col = "#00AFBB")
df1$clust <- cutree(hc, k = 6)
head(df1,10)
```

### 5.2. Mapa de agrupamiento según latitud y longitud.

Para la realización del mapa de agrupamiento según latitud y longitud, se descargó un archivo .shp del Límite Catastral de Comunas y Corregimientos.

```{r message=FALSE, warning=FALSE , echo=T}
s <- shapefile("Limite_Catastral_de__Comunas_y_Corregimientos.shp")
map.df1 <- (s)
ggplot(map.df1)+
  geom_path(aes(x=long, y=lat, group=group))+
  geom_point(data=df1, aes(x=long, y=lat, color=factor(clust)), size=4)+
  scale_color_discrete("Cluster")+
  coord_fixed()
```

El anterior mapa muestra una posible agrupación, según las medidas geoespaciales de la latitud y la longitud de los accidentes. Sin embargo, este agrupamiento se utiliza como referencia porque para su creación no se utilizó ningún método para la elección del $K$ óptimo.

Así que se procede a realizar una clusterización del número de accidentes por Gravedad y Barrio haciendo uso del algoritmo "k means" para la búsqueda del $K$ óptimo.

### 5.3. Clusterización con número de accidentes por gravedad y barrio.

Con los datos preprocesados y el subconjunto de datos que se seleccionaron, Se les realizó un escalamiento y centrado de la base de datos.

```{r message=FALSE, warning=FALSE , echo=T}
#Numero de accidentes por Barrio
datos_cluster <- base_final03 %>% group_by(BARRIO) %>% dplyr::count(name = "TOTAL_ACCIDENTES")

#Número de accidentes por barrio, según gravedad almacenado en 'df'
df <- as.matrix(table(base_final03$BARRIO, base_final03$GRAVEDAD))
df <- data.frame(Con_heridos = df[,1], Con_muertos = df[,2], Solo_danos = df[,3])

#Escalamiento y centrado de la base de datos.
scaled_data = as.matrix(scale(df))
head(scaled_data, 10)
kmm = kmeans(scaled_data, 5, nstart = 50, iter.max = 15 )

```

Para este caso, con un k=5, se evidencia que el valor de Suma de Cuadrados entre grupos (SS between) sobre la Suma de Cuadrados Totales fue de aproximadamente 85.1% (0.851), que indica un buen ajuste porque es cercano a 1. Sin embargo, es mejor graficar el WSS contra el número de clúster, ya que este número se debe especificar de antemano.

Luego se procede a hallar el k óptimo.

### 5.4. El método del codo

```{r message=FALSE, warning=FALSE , echo=T}
#Se fijó una semilla y se realizó el cálculo y se gráficó el WSS(total within - cluster sum of square) para k = 2 hasta k = 10
set.seed(2021022)
k.max <- 10
datos <- scaled_data
wss <- sapply(2:k.max, 
              function(k){kmeans(datos, k, nstart = 50, iter.max = 15 )$tot.withinss})
plot(2:k.max, wss, 
     type = "b", pch = 19, frame = FALSE,
     xlab = "Número de Clusters (k)",
     ylab = "WSS Total", 
     main = "Método del Codo", col="forestgreen")
```

```{r message=FALSE, warning=FALSE, results = 'hide', echo=F}
#Con k=5, se obtiene between_SS / total_SS =  85.1 %) almacenado en 'km'
km <- kmeans(datos, 5)
```

Según la gráfica del Método del Codo posiblemente el k=4 o k=5 serían buenos candidatos para el k óptimo, ya que presentan un cambio más suave en las pendientes en comparación con k=2 o k=3. Igualmente al observar el between SS / total SS para k=5, mencionado anteriomente, se evidencia un 85.1 %, lo cual indica un buen ajuste. Además como se graficó el WSS contra el número de clústeres, se refleja que es un buen candidato.

Después, se busca el $K$ óptimo haciendo uso del paquete NbClust, de la siguiente forma:

```{r message=FALSE, warning=FALSE , echo=T}
nb <- NbClust(scaled_data, diss=NULL, distance = "euclidean", 
              min.nc=4, max.nc=8, method = "kmeans", 
              index = "all", alphaBeale = 0.1)
```
El cual sugiere que el $K$ óptimo es 4.


```{r message=FALSE, warning=FALSE , echo=T }
hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])), main = "Histograma del K óptimo ", xlab = "K", ylab = "Frecuencia", col="darkorchid4")
```

Según el histograma, también indica que el $K$ óptimo es el 4.

### 5.5. Resúmen de métodos

En este resumen se encuentra el método de la Silueta, el Método del Codo y Gap Statistic. Donde se obtuvieron los siguientes resultados:

### 5.5.1. Método de la silueta.
```{r message=FALSE, warning=FALSE , echo=T}
fviz_nbclust(scaled_data, kmeans, method = c("silhouette"))
```

### 5.5.2. Método del codo.
```{r message=FALSE, warning=FALSE , echo=T}
fviz_nbclust(scaled_data, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Método del Codo")
```

### 5.5.3. Gap statistic
```{r message=FALSE, warning=FALSE , echo=T}
set.seed(123)
fviz_nbclust(scaled_data, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  labs(subtitle = "Gap statistic method")
```

### 5.9. Generación de clusterización, según el k óptimo.

Según los diferentes métodos $k = 4$, parecía ser muy óptimo para la generación de la clusterización.

Luego, se muestran las primeras 10 observaciones de los barrios ordenados alfabéticamente, donde se observa el tipo de gravedad y el grupo al cual pertenecen.

```{r message=FALSE, warning=FALSE , echo=T }
kmm = kmeans(scaled_data, 4, nstart = 50, iter.max = 15 )

df_clust <- data.frame(Con_heridos = df[,1], Con_muertos = df[,2], Solo_danos = df[,3], kmm$cluster)
head(df_clust, 10)

```

Con lo realizado anteriormente poseemos el agrupamiento según el k óptimo igual a 4, es decir, ahora los barrios pertenecen a un tipo de cluster (enumaredado del 1 al 4). Para el nombramiento de cada grupo se tomó como referencia el mapa de calor, quedando de la siguiente forma:

- Grupo 1: Accidentalidad Moderada
- Grupo 2: Accidentalidad Baja
- Grupo 3: Accidentalidad Alta
- Grupo 4: Accidentalidad Media-Alta

La información que se obtuvo de cada grupo es la siguiente:

#### 5.9.1. Grupo 1 - accidentalidad moderada

```{r message=FALSE, warning=FALSE , echo=T}
#Accidentalidad Moderada
dfclust_clust1 <- df_clust[df_clust$kmm.cluster == 1, ]
dfclust_clust1$total <- rowSums(dfclust_clust1[,1:3])
sum(dfclust_clust1$Con_heridos)
sum(dfclust_clust1$Con_muertos)
sum(dfclust_clust1$Solo_danos)
sum(dfclust_clust1$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 27895, la cantidad de accidentes con heridos es de 13145, la cantidad de accidentes con muertos 111 y la cantidad de accidentes con solo daños es de 14639.

#### 5.9.2. Grupo 2 - accidentalidad baja

```{r message=FALSE, warning=FALSE , echo=T}
#Accidentalidad Baja
dfclust_clust2 <- df_clust[df_clust$kmm.cluster == 2, ]
dfclust_clust2$total <- rowSums(dfclust_clust2[,1:3])
sum(dfclust_clust2$Con_heridos)
sum(dfclust_clust2$Con_muertos)
sum(dfclust_clust2$Solo_danos)
sum(dfclust_clust2$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 28622, la cantidad de accidentes con heridos es de 17817, la cantidad de accidentes con muertos 106 y la cantidad de accidentes con solo daños es de 10699.

#### 5.9.3. Grupo 3 - accidentalidad alta

```{r message=FALSE, warning=FALSE , echo=T}
#Accidentalidad Alta
dfclust_clust3 <- df_clust[df_clust$kmm.cluster == 3, ]
dfclust_clust3$total <- rowSums(dfclust_clust3[,1:3])
sum(dfclust_clust3$Con_heridos)
sum(dfclust_clust3$Con_muertos)
sum(dfclust_clust3$Solo_danos)
sum(dfclust_clust3$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 36247, la cantidad de accidentes con heridos es de 17147, la cantidad de accidentes con muertos 237 y la cantidad de accidentes con solo daños es de 18863.

#### 5.9.4. - accidentalidad media-alta

```{r message=FALSE, warning=FALSE , echo=T}
#Accidentalidad Media-Alta
dfclust_clust4 <- df_clust[df_clust$kmm.cluster == 4, ]
dfclust_clust4$total <- rowSums(dfclust_clust4[,1:3])
sum(dfclust_clust4$Con_heridos)
sum(dfclust_clust4$Con_muertos)
sum(dfclust_clust4$Solo_danos)
sum(dfclust_clust4$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 54841, la cantidad de accidentes con heridos es de 32887, la cantidad de accidentes con muertos 222 y la cantidad de accidentes con solo daños es de 21732.

Finalmente, se realizó el mapa de agrupamiento, según lo mostrado anteriormente.

### 5.10. Mapa de accidentalidad en la ciudad de Medellín por agrupamiento

```{r message=FALSE, warning=FALSE , echo=T}
#Se vuelve a utlizar catastro para este mapa

#Se importó el archivo .xlsx basemapa

basemapa <- read_excel("basemapa.xlsx")
base_mapa <- data_frame(basemapa)

catastro$CODIGO <- as.numeric(as.character(catastro$CODIGO))
base_mapa$Codigo <- as.numeric(as.character(base_mapa$Codigo))

#Se utilizó 'inner join' de nuevo para unir dos bases y para así luego generar mapa

mapa02 <- inner_join(catastro, base_mapa, by = c("CODIGO" = "Codigo"))

colorgrupos <- c("#00FF66", "#CCFF00", "#FF0000", "#0066FF")
mapa02$colores <- ifelse(mapa02$kmm.cluster == "1", "#00FF66",
                            ifelse(mapa02$kmm.cluster == "2", "#CCFF00",
                                   ifelse(mapa02$kmm.cluster == "3", "#FF0000",
                                          ifelse(mapa02$kmm.cluster == "4", "#0066FF",0))))

#Mapa final
leaflet() %>% addPolygons(data = mapa02, opacity = 0.4, color = "#545454",weight = 1, fillColor = mapa02$colores,
                          fillOpacity = 0.4, label = ~NOMBRE_BAR,
                          highlightOptions = highlightOptions(color = "#262626", weight = 3, bringToFront = T, opacity = 1),
                          popup = paste("Barrio: ", mapa02$NOMBRE_BAR, "<br>", "Grupo: ", mapa02$kmm.cluster, "<br>", "Número de Accidentes con heridos: ", mapa02$Con_heridos, "<br>", "Número de Accidentes con muertos: ", mapa02$Con_muertos, "<br>", "Número de Accidentes con solo daños: ", mapa02$Solo_danos)) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addLegend(position = "bottomright", colors = colorgrupos, labels = c("Grupo 1: Accidentalidad Moderada", "Grupo 2: Accidentalidad Baja", "Grupo 3: Accidentalidad Alta", "Grupo 4: Accidentalidad Media-Alta"))

```




------------------------------------------------------------------

## 6. Conclusiones  

*  El lunes, es el día de la semana que más accidentes se presentan en la ciudad de Medellín.

*  El modelo lineal generalizado con la familia de distribución Poisson y con la adición de la variable Clase, demostró eficiencía y es un buen candidato para predecir la accidentalidad en Medellín. Con los resultados obtenidos, no se observaron problemas de sobreentrenamiento para este modelo. 
*  La mayor cantidad de accidentes ocurren en la comuna La Candelaria. La zona centro y las vías principales son las más afectadas por los accidentes.


------------------------------------------------------------------

## 7. Comentarios  

*  Con un poco más de tiempo, se podrían implementar modelos con redes neuronales o también con potenciación del gradiente.

*  Seria interesante analizar los datos actuales con una nueva variable que nos indique el estado del clima del día en que ocurrió el accidente. Podriamos definir una variable que puede tener las etiquetas `día soleado` ó `día lluvioso`, y de esta forma verificar el comportamiento de los accidente dependiendo del clima.  



------------------------------------------------------------------


## 8. Enlaces



Es importante resaltar que este reporte trae consigo dos elementos adicionales complementarios:

* Un [Repositorio en Github](https://github.com/daatoroag/PROYECTOS-TAE), donde usted puede acceder a las bases de datos utilizadas a lo largo del reporte, y también a todos los scripts utilizados para obtener los resultados.
* Una [Aplicación web](http://accidentalidad-medallo.shinyapps.io/) elaborada con R Shiny Web App, en donde usted puede seleccionar una ventana de tiempo y obtener los datos históricos de accidentalidad por tipo de accidente. También podrá predecir la accidentalidad por tipo de accidente, visualizar los grupos de barrios, entre otras.



------------------------------------------------------------------

## 9. Referencias

[1]Incidentes viales. consultado el 18/11/2021. URL: http://medata.gov.co/dataset/incidentes-viales

[2]Alcaldía de Medellín OpenData, URL: https://geomedellin-m-medellin.opendata.arcgis.com/datasets/M-Medellin::limite-barrio-vereda-catastral/about

[3]R Markdown Cookbook, Yihui Xie, Christophe Dervieux, Emily Riederer (2021). URL:https://bookdown.org/yihui/rmarkdown-cookbook/

[4]Modelación de la Accidentalidad vehicular para las 16 comunas del área urbana de Medellín entre los años 2014-2019 a través de regresión multinivel. Juan Felipe Múnera Vergara (2020). URL:https://rpubs.com/JMra99/589734

[5]Accidentalidad de Motocicleta en Medellín - años 2015 a 2019. Edimer (2019), URL:https://rpubs.com/Edimer/534624

[6]Técnicas estadísticas para analizar y pronósticar información de accidentalidad en Medellín entre los años 2014 y 2018. (Agudelo, Vergara y Gaviaria et. al.)(2020). URL:https://rpubs.com/saagudeloga2020/692755

[7]R Markdown Theme Gallery. Andrew Zieffler (2018). URL: https://www.datadreaming.org/post/r-markdown-theme-gallery/

