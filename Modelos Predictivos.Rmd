---
title: "Modelos Predictivos"
author: "Kleider Stiven Vásquez Gómez y Jelssin Donnovan Robledo Mena"
date: "23/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Primer Trabajo de Técnicas en Aprendizaje Estadístico

```{r }
#Instalación y lectura de librerías

#install.packages("dummies", "stringr", "dplyr", "lubridate", "ggplot2", "GGally", "car", "MLmetrics", "wordcloud", "gplots", "R.utils", "tm", "DescTools", "raster", "mclust", "rgdal", "raster", "geosphere", "NbClust", "factoextra", "vegan", "qpcR")

#Los siguientes paquetes son los que se necesitan para el trabajo Número 01 de TAE

library(dummies)
library(stringr)
library(readxl)
library(sf)
library(dplyr)
library(lubridate)
library(ggplot2)
library(GGally)
library(car)
library(MLmetrics)
library(wordcloud)
library(gplots)
library(R.utils)
library(tm)
library(DescTools)
library(raster)
library(mclust)
library(rgdal)
library(raster)
library(geosphere)
library(NbClust)
library(factoextra)
library(vegan)
library(qpcR)
library(leaflet)
```

```{r}
#Lectura de la Base de datos con la cual se trabajará en este proyecto
base_final <- read.csv("base_final.csv", encoding="UTF-8")
```

### 1 - Entrenamiento de un Modelo Predictivo

En la etapa de entrenamiento del modelo predictivo se utilizó el registro histórico de accidentes desde el año 2014 hasta el año 2017, y para la etapa de validación se hizo uso de los registros de los años 2018 y 2019. Ésto debido a las especificaciones del trabajo para predecir la accidentalidad en Medellín.

### Modelo Lineal

Inicialmente se utiliza un modelo lineal con las variables "Festividad", "Día Semana" y "Diseño".

```{r }
#Modelo lineal
base_final$CLASE <- as.factor(as.character(base_final$CLASE))
datos_vl <- subset(base_final, (AÑO == '2018'))
base_final01 <- subset(base_final, (AÑO != '2018'))
base_final02 <- subset(base_final01, (AÑO != '2019'))
base_final03 <- subset(base_final02, (AÑO != '2020'))

datos_lm1 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   DISENO) %>% count(name = "NRO_ACCID") 
lm1 <- lm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA+DISENO, data = datos_lm1)
promedio <- mean(datos_lm1$NRO_ACCID)
TSS <- sum((datos_lm1$NRO_ACCID - promedio)^2)
RSS <- RSS(lm1)
r2 <- 1-RSS/TSS
RSS2 <- anova(lm1)[4, 2]
r2 <- 1-RSS/TSS
```

En este modelo se va a observar el **MSE** (Error Cuadrático Medio) y el **$R^2$** (Coeficiente de Determinación) para determinar la potencia del modelo para predecir.

### Predicción y Evaluación para los datos de Entrenamiento

```{r }
lm1_data <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   DISENO) %>% count(name = "NRO_ACCID") 
lm1_tr <- lm1_data[,-c(5)]

predicted <- round(predict(lm1, newdata=lm1_tr))
actual <- lm1_data$NRO_ACCID

lm1_mse <- MSE(predicted, actual) # MSE
lm1_mae <- MAE(predicted, actual) # MAE
lm1_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm1_mse, lm1_mae, lm1_r2)

```
### Predicción y Evaluación para los datos de Validación en el año 2018

```{r }

lm1_2018 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                  DISENO) %>% count(name = "NRO_ACCID")

predicted <- round(predict(lm1, newdata=lm1_2018))
actual <- lm1_2018$NRO_ACCID

lm1_mse <- MSE(predicted, actual) # MSE
lm1_mae <- MAE(predicted, actual) # MAE
lm1_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm1_mse, lm1_mae, lm1_r2)

```
La diferencia del MSE entre los datos de entrenamiento y validación del 2018 es del 34.48%, que al ser mayor que el 15% indica un posible sobreajuste. Además se puede apreciar que el $R^2$ de los datos de validación para el año 2018 predice un 72.86%, sin embargo disminuyó un 16.82% en cuanto al $R^2$ para los datos de entrenamiento. Así que luego de ésto se decide igualmente ver qué sucede con el mismo modelo validando con el año 2019.

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r }

datos_vl02 <- subset(base_final, (AÑO == '2019'))

lm1_2019 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                  DISENO) %>% count(name = "NRO_ACCID")

predicted <- round(predict(lm1, newdata=lm1_2019))
actual <- lm1_2019$NRO_ACCID

lm1_mse <- MSE(predicted, actual) # MSE
lm1_mae <- MAE(predicted, actual) # MAE
lm1_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm1_mse, lm1_mae, lm1_r2)

```

La diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 41.29%, que al ser mayor que el 15% indica un posible sobreajuste. Además se puede evidenciar que el $R^2$ de los datos de validación para el año 2019 predice un 76.53%, sin embargo aunque mejoró con respecto a la validación del año 2018, disminuyó un 13.15% en cuanto al $R^2$ para los datos de entrenamiento. Por tanto, al obtener estos resultados validando con los años 2018 y 2019 se decide buscar un nuevo modelo cambiando las variables.

## Modelo Lineal con disminución de Variables

Para este nuevo modelo se decide utilizar un modelo lineal únicamente con las variables "Festividad" y "Día Semana". Es decir, se omite en este caso "Diseño" para observar qué cambios pueden ocurrir en el modelo.

```{r}
datos_lm2 <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

lm2 <- lm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA, data = datos_lm2)

```

### Predicción y Evaluación para los datos de Entrenamiento

```{r}
lm2_tr <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

predicted <- round(predict(lm2, newdata=lm2_tr))
actual <- lm2_tr$NRO_ACCID

lm2_mse <- MSE(predicted, actual) # MSE
lm2_mae <- MAE(predicted, actual) # MAE
lm2_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm2_mse, lm2_mae, lm2_r2)
```
### Predicción y Evaluación para los datos de Validación en el año 2018

```{r}
lm2_2018 <- datos_vl %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

predicted <- round(predict(lm2, newdata=lm2_2018))
actual <- lm2_2018$NRO_ACCID

lm2_mse <- MSE(predicted, actual) # MSE
lm2_mae <- MAE(predicted, actual) # MAE
lm2_r2 <- R2_Score(predicted, actual) # R2


sprintf("MSE: %f, MAE: %f, R2: %f", lm2_mse, lm2_mae, lm2_r2)
```
Con este nuevo modelo disminuyendo variables no se obtuvieron resultados positivos, ya que el R2 disminuyó notablemente tanto en el entrenamiento, como en la validación con el año 2018 y la diferencia entre el MSE de datos de entrenamiento y validación para el año 2018 fue de 57.89%, lo cual indica que aumentó, indicando así una alta variabilidad en cuanto a las predicciones y de esa forma, una baja variabilidad explicada por este nuevo modelo.

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r }

lm2_2019 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

predicted <- round(predict(lm2, newdata=lm2_2019))
actual <- lm2_2019$NRO_ACCID

lm2_mse <- MSE(predicted, actual) # MSE
lm2_mae <- MAE(predicted, actual) # MAE
lm2_r2 <- R2_Score(predicted, actual) # R2

sprintf("MSE: %f, MAE: %f, R2: %f", lm2_mse, lm2_mae, lm2_r2)

```

Para este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 91.02%, que claramente indica un sobreajuste. Y se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 10.07%. Así que se concluye que este modelo no sirve para predecir según los resultados obtenidos tanto en el entrenamiento, como para la validación en los años de 2018 y 2019. Así que se decide utilizar un modelo lineal generalizado.

## Modelo Lineal Generalizado

```{r}
datos_lm3 <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

lm3 <- glm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA, family = "poisson", data = datos_lm3) # Modelo lineal generalizado, con familia poisson

```

### Predicción y Evaluación para los datos de Entrenamiento

```{r}
lm3_tr <- base_final03 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

lm3_tr_1 <- lm3_tr[,-4]

predicted <- round(predict(lm3, newdata=lm3_tr_1, type="response"))
actual <- lm3_tr$NRO_ACCID

lm3_mse <- MSE(predicted, actual) # MSE
lm3_mae <- MAE(predicted, actual) # MAE
lm3_r2 <- R2_Score(predicted, actual)

sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm3_mse, lm3_mae, lm3_r2)
```

### Predicción y Evaluación para los datos de Validación en el año 2018

```{r}
lm3_2018 <- datos_vl %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

predicted <- round(predict(lm3, newdata=lm3_2018, type="response")) 
actual <- lm3_2018$NRO_ACCID

lm3_mse <- MSE(predicted, actual) # MSE
lm3_mae <- MAE(predicted, actual) # MAE
lm3_r2 <- R2_Score(predicted, actual)

sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm3_mse, lm3_mae, lm3_r2)
```

En este modelo lineal generalizado con la familia de distribución Poisson se obtuvo un $R^2$ en la etapa de entrenamiento de 7.21%, y para la etapa de validación para el año 2018 el $R^2$ fue de 2.88%,lo cual indica que dicho modelo no sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 57.89%, que indica un sobreajuste. Sin embargo se procede a validar igualmente con el año 2019.

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r}
lm3_2019 <- datos_vl02 %>% group_by(FECHA,FESTIVIDAD, DIA_SEMANA) %>% 
  count(name = "NRO_ACCID")

predicted <- round(predict(lm3, newdata=lm3_2019, type="response")) 
actual <- lm3_2019$NRO_ACCID

lm3_mse <- MSE(predicted, actual) # MSE
lm3_mae <- MAE(predicted, actual) # MAE
lm3_r2 <- R2_Score(predicted, actual)

sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm3_mse, lm3_mae, lm3_r2)
```

Para este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 90.91%, que claramente indica un sobreajuste. Y se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 10.1%. Así que se evidencia que este modelo no sirve para predecir según los resultados obtenidos tanto en el entrenamiento, como para la validación en los años de 2018 y 2019. Así que se decide utilizar el modelo lineal generalizado adicinando otra variable.

## Modelo lineal generalizado con Adición de la variable Clase

```{r}
datos_lm4 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   CLASE) %>% count(name = "NRO_ACCID")

lm4 <- glm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA+CLASE, family = "poisson", 
           data = datos_lm4)
```

### Predicción y Evaluación para los datos de Entrenamiento

```{r}
datos_lm4_p <- datos_lm4[,-5]
y_train <- round(predict(lm4, newdata= datos_lm4_p, type="response"))
y_actual <- datos_lm4$NRO_ACCID
lm4_tmse <- MSE(y_train, y_actual)
lm4_tmae <-  MAE(y_train, y_actual)
lm4_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm4_tmse, lm4_tmae, lm4_r2)
```

### Predicción y Evaluación para los datos de Validación en el año 2018

```{r}
datos_lm4_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE) %>% count(name = "NRO_ACCID")
datos_lm4_v2 <- datos_lm4_v1[,-5]

y_train <- round(predict(lm4, newdata= datos_lm4_v2, type="response"))
y_actual <- datos_lm4_v1$NRO_ACCID
lm4_tmse <- MSE(y_train, y_actual)
lm4_tmae <-  MAE(y_train, y_actual)
lm4_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm4_tmse, lm4_tmae, lm4_r2)

```

En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Clase se obtuvo un $R^2$ en la etapa de entrenamiento de 88.6%,y para la etapa de validación para el año 2018 el $R^2$ fue de 89.51%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 10.03%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Luego se procede a validar con el año 2019. 

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r}
datos_lm4_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE) %>% count(name = "NRO_ACCID")
datos_lm4_v2 <- datos_lm4_v1[,-5]

y_train <- round(predict(lm4, newdata= datos_lm4_v2, type="response"))
y_actual <- datos_lm4_v1$NRO_ACCID
lm4_tmse <- MSE(y_train, y_actual)
lm4_tmae <-  MAE(y_train, y_actual)
lm4_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm4_tmse, lm4_tmae, lm4_r2)

```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 0.94%, que fue menor al valor obtenido con la validación del 2018 (10.03%), que indica claramente que no hay problemas de sobreentrenamiento. Además se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 88.63%, evidenciando así que este modelo lineal generalizado con la adición de la variable Clase es un buen candidato para predecir la accidentalidad en Medellín. Sin embargo, se adicionará otra variable para ver si se obtiene un mejor modelo.

## Modelo lineal generalizado con Adición de la variable Diseño

```{r}

datos_lm5 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                   CLASE, DISENO) %>% count(name = "NRO_ACCID")

lm5 <- glm(NRO_ACCID ~ FESTIVIDAD+DIA_SEMANA+CLASE+DISENO, family = "poisson", 
           data = datos_lm5)
```

### Predicción y Evaluación para los datos de Entrenamiento

```{r}
datos_lm5_p <- datos_lm5[,-6]
y_train <- round(predict(lm5, newdata= datos_lm5_p, type="response"))
y_actual <- datos_lm5$NRO_ACCID
lm5_tmse01 <- MSE(y_train, y_actual)
lm5_tmae <-  MAE(y_train, y_actual)
lm5_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm5_tmse01, lm5_tmae, lm5_r2)
```
### Predicción y Evaluación para los datos de Validación en el año 2018

```{r}
datos_lm5_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE, DISENO) %>% count(name = "NRO_ACCID")
datos_lm5_v2 <- datos_lm5_v1[,-6]

y_train <- round(predict(lm5, newdata= datos_lm5_v2, type="response"))
y_actual <- datos_lm5_v1$NRO_ACCID
lm5_tmse02 <- MSE(y_train, y_actual)
lm5_tmae <-  MAE(y_train, y_actual)
lm5_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm5_tmse02, lm5_tmae, lm5_r2)
```
En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Diseño se obtuvo un $R^2$ en la etapa de entrenamiento de 86.56%, y para la etapa de validación para el año 2018 el $R^2$ fue de 81.93%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. La diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 4.92%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Así, se procede a validar con el año 2019. 

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r}
datos_lm5_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, DIA_SEMANA, 
                                      CLASE, DISENO) %>% count(name = "NRO_ACCID")
datos_lm5_v2 <- datos_lm5_v1[,-6]

y_train <- round(predict(lm5, newdata= datos_lm5_v2, type="response"))
y_actual <- datos_lm5_v1$NRO_ACCID
lm5_tmse02 <- MSE(y_train, y_actual)
lm5_tmae <-  MAE(y_train, y_actual)
lm5_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm5_tmse02, lm5_tmae, lm5_r2)
```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del 3.4%, que indica que no hay problemas de sobreentrenamiento. También se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 82.91%, que evidencia que este modelo lineal generalizado con la adición de la variable Diseño es buen candidato para predecir la accidentalidad en Medellín.

Este modelo presenta el mejor MSE, pero no es un modelo viable ya que no es posible obtener la variable DISENO para realizar predicciones, según las pautas dadas.

Finalmente, se decide trabajar con el modelo lineal generalizado que posee la variable CLASE, ya que como se analizó anteriormente, se observa que tanto para los datos de entrenamiento, como para los de validación (2018, 2019) se pueden obtener buenas predicciones.

Luego, con el modelo elegido se procedió a realizar la etapa de entrenamiento y validación de forma semanal y mensual ya que dicho modelo para la predicción diaria tuvo buenos resultados, tanto para el MSE, como para el $R^2$, para así observar si también con dicho modelo se pueden obtener buenas predicciones no solamente de manera diaria.

## Semanal

## Modelo lineal generalizado con Adición de la variable Clase

```{r}
datos_lm6 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, SEMANA, 
                                   CLASE) %>% count(name = "NRO_ACCID")

lm6 <- glm(NRO_ACCID ~ FESTIVIDAD+SEMANA+CLASE, family = "poisson", 
           data = datos_lm6)
```

### Predicción y Evaluación para los datos de Entrenamiento

```{r}
datos_lm6_p <- datos_lm6[,-5]
y_train <- round(predict(lm6, newdata= datos_lm6_p, type="response"))
y_actual <- datos_lm6$NRO_ACCID
lm6_tmse <- MSE(y_train, y_actual)
lm6_tmae <-  MAE(y_train, y_actual)
lm6_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm6_tmse, lm6_tmae, lm6_r2)
```

### Predicción y Evaluación para los datos de Validación en el año 2018

```{r}
datos_lm6_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, SEMANA, 
                                      CLASE) %>% count(name = "NRO_ACCID")
datos_lm6_v2 <- datos_lm6_v1[,-5]

y_train <- round(predict(lm6, newdata= datos_lm6_v2, type="response"))
y_actual <- datos_lm6_v1$NRO_ACCID
lm6_tmse <- MSE(y_train, y_actual)
lm6_tmae <-  MAE(y_train, y_actual)
lm6_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm6_tmse, lm6_tmae, lm6_r2)

```

En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Clase se obtuvo un $R^2$ en la etapa de entrenamiento de 96.63%,y para la etapa de validación para el año 2018 el $R^2$ fue de 87.48%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 10.43%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Luego se procede a validar con el año 2019. 

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r}
datos_lm6_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, SEMANA, 
                                      CLASE) %>% count(name = "NRO_ACCID")
datos_lm6_v2 <- datos_lm6_v1[,-5]

y_train <- round(predict(lm6, newdata= datos_lm6_v2, type="response"))
y_actual <- datos_lm6_v1$NRO_ACCID
lm6_tmse <- MSE(y_train, y_actual)
lm6_tmae <-  MAE(y_train, y_actual)
lm6_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm6_tmse, lm6_tmae, lm6_r2)

```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del  1.27%, que fue menor al valor obtenido con la validación del 2018 (10.43%), que indica claramente que no hay problemas de sobreentrenamiento. Además se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 88.83%, evidenciando así que este modelo lineal generalizado con la adición de la variable Clase es un buen candidato para predecir la accidentalidad en Medellín.


## Mensual

## Modelo lineal generalizado con Adición de la variable Clase

```{r}
datos_lm7 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, MES, 
                                   CLASE) %>% count(name = "NRO_ACCID")

lm7 <- glm(NRO_ACCID ~ FESTIVIDAD+MES+CLASE, family = "poisson", 
           data = datos_lm7)
```

### Predicción y Evaluación para los datos de Entrenamiento

```{r}
datos_lm7_p <- datos_lm7[,-5]
y_train <- round(predict(lm7, newdata= datos_lm7_p, type="response"))
y_actual <- datos_lm7$NRO_ACCID
lm7_tmse <- MSE(y_train, y_actual)
lm7_tmae <-  MAE(y_train, y_actual)
lm7_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", 
        lm7_tmse, lm7_tmae, lm7_r2)
```

### Predicción y Evaluación para los datos de Validación en el año 2018

```{r}
datos_lm7_v1 <- datos_vl %>% group_by(FECHA, FESTIVIDAD, MES, 
                                      CLASE) %>% count(name = "NRO_ACCID")
datos_lm7_v2 <- datos_lm7_v1[,-5]

y_train <- round(predict(lm7, newdata= datos_lm7_v2, type="response"))
y_actual <- datos_lm7_v1$NRO_ACCID
lm7_tmse <- MSE(y_train, y_actual)
lm7_tmae <-  MAE(y_train, y_actual)
lm7_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm7_tmse, lm7_tmae, lm7_r2)

```

En este modelo lineal generalizado con la familia de distribución Poisson con adición de la variable Clase se obtuvo un $R^2$ en la etapa de entrenamiento de 96.6%,y para la etapa de validación para el año 2018 el $R^2$ fue de 94.41%,lo cual indica que dicho modelo sirve para predecir según los resultados obtenidos. Además la diferencia entre el MSE de entrenamiento y validación para el año 2018 fue de 2.19%, lo que indica que al ser menor del 15% no hay problemas de sobreentrenamiento. Luego se procede a validar con el año 2019. 

### Predicción y Evaluación para los datos de Validación en el año 2019

```{r}
datos_lm7_v1 <- datos_vl02 %>% group_by(FECHA, FESTIVIDAD, MES, 
                                      CLASE) %>% count(name = "NRO_ACCID")
datos_lm7_v2 <- datos_lm7_v1[,-5]

y_train <- round(predict(lm7, newdata= datos_lm7_v2, type="response"))
y_actual <- datos_lm7_v1$NRO_ACCID
lm7_tmse <- MSE(y_train, y_actual)
lm7_tmae <-  MAE(y_train, y_actual)
lm7_r2 <- R2_Score(y_train, y_actual)
sprintf("MSE: %f, MAE: %f, R2 Score: %f", lm7_tmse, lm7_tmae, lm7_r2)

```

En este modelo la diferencia del MSE entre los datos de entrenamiento y validación del 2019 es del  1.3%, que fue menor al valor obtenido con la validación del 2018 (2.19%), que indica claramente que no hay problemas de sobreentrenamiento. Además se puede observar que el $R^2$ de los datos de validación para el año 2019 predice un 88.83%, evidenciando así que este modelo lineal generalizado con la adición de la variable Clase es un buen candidato para predecir la accidentalidad en Medellín.

## Predicciones

## Predicción Diaria del 2020

```{r}
Base_prediccion <- read.csv("prediccion.csv", sep = ",", encoding = "UTF-8")

Base_prediccion <- Base_prediccion[,-1]

Base_prediccion_2020 <- subset(Base_prediccion, (AÑO != '2021'))

Base_prediccion_2020$FECHA <- as.Date(Base_prediccion_2020$FECHA)
Base_prediccion_2020$CLASE <- as.factor(Base_prediccion_2020$CLASE)
Base_prediccion_2020$DIA_SEMANA <- as.factor(Base_prediccion_2020$DIA_SEMANA)
Base_prediccion_2020$AÑO <- as.integer(Base_prediccion_2020$AÑO)
Base_prediccion_2020$FESTIVIDAD <- as.factor(Base_prediccion_2020$FESTIVIDAD)

prediccion_2020 <- predict(object = lm4, newdata = Base_prediccion_2020,
                          type = "response")
prediccion_diaria2020 <- Base_prediccion_2020 %>% 
  mutate(NRO_ACCID = round(prediccion_2020,0))

head(prediccion_diaria2020, 10)

```

## Predicción Diaria del 2021

```{r}
Base_prediccion_2021 <- subset(Base_prediccion, (AÑO != '2020'))

Base_prediccion_2021$FECHA <- as.Date(Base_prediccion_2021$FECHA)
Base_prediccion_2021$CLASE <- as.factor(Base_prediccion_2021$CLASE)
Base_prediccion_2021$DIA_SEMANA <- as.factor(Base_prediccion_2021$DIA_SEMANA)
Base_prediccion_2021$AÑO <- as.integer(Base_prediccion_2021$AÑO)
Base_prediccion_2021$FESTIVIDAD <- as.factor(Base_prediccion_2021$FESTIVIDAD)

prediccion_2021 <- predict(object = lm4, newdata = Base_prediccion_2021,
                          type = "response")
prediccion_diaria2021 <- Base_prediccion_2021 %>% 
  mutate(NRO_ACCID = round(prediccion_2021,0))

head(prediccion_diaria2021, 10)

```

## Predicción Semanal del 2020

```{r}

Base_prediccion03 <- Base_prediccion[,-4]
Base_prediccion04 <- Base_prediccion03[,-4]

Base_prediccion_2020 <- subset(Base_prediccion, (AÑO != '2021'))

Base_prediccion_2020 <- subset(Base_prediccion04, (AÑO != '2021'))


Base_prediccion_2020$SEMANA <- as.integer(Base_prediccion_2020$SEMANA)


prediccion_2020_02 <- predict(object = lm6, newdata = Base_prediccion_2020,
                          type = "response")
prediccion_semanal2020 <- Base_prediccion_2020 %>% 
  mutate(NRO_ACCID = round(prediccion_2020_02,0))

head(prediccion_semanal2020, 10)

#summary(Base_prediccion03$SEMANA, Base_prediccion03$CLASE)

semanal <- prediccion_semanal2020 %>% group_by(CLASE, semana = week(FECHA), NRO_ACCID) %>% summarize(total = n())
semanal

#datos_lm7 <- base_final03 %>% group_by(FECHA, FESTIVIDAD, MES, 
#                                   CLASE) %>% count(name = "NRO_ACCID")

semanal <- prediccion_semanal2020 %>% group_by(CLASE, SEMANA, NRO_ACCID) %>% count(name = "NRO_ACCID")

semanal <- prediccion_semanal2020 %>% group_by(SEMANA, 
                                      CLASE, NRO_ACCID)

```

## Predicción Semanal del 2021

```{r}
base_final03 <- subset(base_final02, (AÑO != '2020'))
Base_prediccion_2021 <- subset(Base_prediccion, (AÑO != '2020'))

Base_prediccion_2021$FECHA <- as.Date(Base_prediccion_2021$FECHA)
Base_prediccion_2021$CLASE <- as.factor(Base_prediccion_2021$CLASE)
Base_prediccion_2021$DIA_SEMANA <- as.factor(Base_prediccion_2021$DIA_SEMANA)
Base_prediccion_2021$AÑO <- as.integer(Base_prediccion_2021$AÑO)
Base_prediccion_2021$FESTIVIDAD <- as.factor(Base_prediccion_2021$FESTIVIDAD)

prediccion_2021 <- predict(object = lm4, newdata = Base_prediccion_2021,
                          type = "response")
prediccion_diaria2021 <- Base_prediccion_2021 %>% 
  mutate(NRO_ACCID = round(prediccion_2021,0))

head(prediccion_diaria2021, 10)

```

## Predicción Mensual del 2020

```{r}
Base_prediccion <- read.csv("prediccion.csv", sep = ",", encoding = "UTF-8")

Base_prediccion_2020 <- subset(Base_prediccion, (AÑO != '2021'))

Base_prediccion_2020$FECHA <- as.Date(Base_prediccion_2020$FECHA)
Base_prediccion_2020$CLASE <- as.factor(Base_prediccion_2020$CLASE)
Base_prediccion_2020$DIA_SEMANA <- as.factor(Base_prediccion_2020$DIA_SEMANA)
Base_prediccion_2020$AÑO <- as.integer(Base_prediccion_2020$AÑO)
Base_prediccion_2020$FESTIVIDAD <- as.factor(Base_prediccion_2020$FESTIVIDAD)

prediccion_2020 <- predict(object = lm4, newdata = Base_prediccion_2020,
                          type = "response")
prediccion_diaria2020 <- Base_prediccion_2020 %>% 
  mutate(NRO_ACCID = round(prediccion_2020,0))

head(prediccion_diaria2020, 10)

```

## Predicción Mensual del 2021

```{r}
Base_prediccion_2021 <- subset(Base_prediccion, (AÑO != '2020'))

Base_prediccion_2021$FECHA <- as.Date(Base_prediccion_2021$FECHA)
Base_prediccion_2021$CLASE <- as.factor(Base_prediccion_2021$CLASE)
Base_prediccion_2021$DIA_SEMANA <- as.factor(Base_prediccion_2021$DIA_SEMANA)
Base_prediccion_2021$AÑO <- as.integer(Base_prediccion_2021$AÑO)
Base_prediccion_2021$FESTIVIDAD <- as.factor(Base_prediccion_2021$FESTIVIDAD)

prediccion_2021 <- predict(object = lm4, newdata = Base_prediccion_2021,
                          type = "response")
prediccion_diaria2021 <- Base_prediccion_2021 %>% 
  mutate(NRO_ACCID = round(prediccion_2021,0))

head(prediccion_diaria2021, 10)

```


### 2 - Agrupamiento de los barrios de Medellín de acuerdo a su accidentalidad

Antes de realizar la agrupación de barrios según la accidentalidad se decide mostrar primero un mapa de calor de accidentalidad en la ciudad de Medellín entre los años de 2014 y 2019, ya que este mapa a su vez representaría la historia de la accidentalidad. Lo anterior, teniendo presente que para este proyecto se pretende predecir para los años de 2020 y 2021.

### Mapa de Accidentes en la ciudad de Medellín

Para la elaboración del mapa calor según la accidentalidad, se descargó un archivo .shp del Límite Barrio Vereda Catastral

```{r}
#lectura de .csv y .shp
catastral <- read.csv("Limite_Barrio_Vereda_Catastral.csv", encoding="UTF-8")

catastro <- read_sf("Limite_Barrio_Vereda_Catastral.shp")

barrio_vereda <- read.csv("Barrio_Vereda_2014.csv", encoding="UTF-8")

```

```{r}
#Mapa para todos los barrios, usando 'innerjoin' con el .shp de Limite_Barrio_Vereda_Catastral

Unido <- inner_join(catastral, base_final, by = c("COMUNA" = "NUMCOMUNA"))

nueva_base <- Unido %>% filter(AÑO >= 2014 & AÑO <= 2019) %>% 
  group_by(CODIGO) %>%
  summarise(accidentes = n()) %>%
  ungroup()

#Se realizó la conversión de CODIGO a formato numérico

catastro$CODIGO <- as.numeric(as.character(catastro$CODIGO))

#Se utilizó 'inner join' para unir dos bases y para luego generar mapa

mapa <- inner_join(catastro, nueva_base, by = c("CODIGO" = "CODIGO"))

mypal <- colorNumeric(palette = c("#000000","#280100","#3D0201","#630201","#890100","#B00100","#DD0100","#F50201",
                                   "#FF5F5E","#FF7A79","#FF9796","#FEB1B0","#FDC9C8", "#FFE5E4"), domain = mapa$accidentes, reverse = T)

# Creación del mapa

leaflet() %>% addPolygons(data = mapa, color = "#0A0A0A", opacity = 0.6, weight = 1, fillColor = ~mypal(mapa$accidentes),
                          fillOpacity = 0.6, label = ~NOMBRE_BAR,
                          highlightOptions = highlightOptions(color = "black", weight = 3, bringToFront = T, opacity = 1),
                          popup = paste("Barrio: ", mapa$NOMBRE_BAR, "<br>", "Accidentes: ", mapa$accidentes, "<br>")) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addLegend(position = "bottomright", pal = mypal, values = mapa$accidentes, title = "Accidentes", opacity = 0.6)
```

```{r}
# Cantidad de Accidentes por Comuna

medellin_comuna <- base_final %>% filter(AÑO >= 2014 & AÑO <= 2019) %>% 
  group_by(COMUNA) %>% 
  summarize(accidentes = n())

ggplot(data = medellin_comuna, aes(x = reorder(COMUNA,+accidentes), y = accidentes)) +
  geom_bar(stat = "identity", position = "dodge", fill = "blue", color = "black", alpha = 0.6) +
  geom_text(aes(y = accidentes, label = accidentes),
                position = position_dodge(width = 0.7), size = 3.5, vjust = 0.5, hjust = -0.1, col = "black") +
  xlab("Comuna") + 
  ylab("Total de Accidentes") +
  ggtitle("Total de Accidentes por Comuna entre los años 2014 y 2019") +
  ylim(c(0,50000)) +
  theme_minimal() +
  coord_flip()
```

Al analizar la accidentalidad por Barrio y Comuna, tanto en el mapa de accidentalidad como en el gráfico, se observó que La Candelaria es el lugar donde más se presentan accidentes entre los años 2014 y 2019, seguida por Laureles y Castilla. También, se evidencia que Palmitas es el lugar donde ocurre menos accidentalidad en Medellín durante los años 2014-2019. Además en el mapa de calor se puede notar que la zona centro y las vías principales son las más afectadas por los accidentes.

Luego se procede a crear una función para calular distancias para datos geoespaciales y además se crea un dendograma para así emprender la búsqueda del $K$ óptimo para el agrupamiento (tomando los datos de 2014 hasta 2017, ya que éstos fueron los años que se utilizaron para el modelo de predicción).

```{r}
#Haciendo uso de la librería 'geosphere', se creó una función para calcular las distancias para datos geoespaciales

geo.dist = function(df) {
  require(geosphere)
  d <- function(i,z){         # z[1:2] contain long, lat
    dist <- rep(0,nrow(z))
    dist[i:nrow(z)] <- distHaversine(z[i:nrow(z),1:2],z[i,1:2])
    return(dist)
  }
  dm <- do.call(cbind,lapply(1:nrow(df),d,df))
  return(as.dist(dm))
}
```

```{r }
#Se realizó la conversión de la latitud y longitud al formato numérico

base_final03$LATITUD <- as.numeric(as.character(base_final03$LATITUD))
base_final03$LONGITUD<- as.numeric(as.character(base_final03$LONGITUD))
```

```{r }
#Se creó un nuevo dataset para el agrupamiento, según longitud, latitud y barrio almacenado en 'df'
df <- data.frame(long = base_final03$LONGITUD, lat = base_final03$LATITUD, barrios = base_final03$BARRIO)
```

```{r}
#Se creó con la función 'geo.dist', una matriz de distancias
df1 <- df[1:1000, ]
d <- geo.dist(df1)
hc <- hclust(d)
plot(hc, main = "Dendograma", col = "#00AFBB")
df1$clust <- cutree(hc, k = 6)
head(df1,10)
```

### Mapa de agrupamiento según latitud y longitud.

Para la realización del mapa de agrupamiento según latitud y longitud, se descargó un archivo .shp del Límite Catastral de Comunas y Corregimientos.

```{r}
s <- shapefile("Limite_Catastral_de__Comunas_y_Corregimientos.shp")
map.df1 <- (s)
ggplot(map.df1)+
  geom_path(aes(x=long, y=lat, group=group))+
  geom_point(data=df1, aes(x=long, y=lat, color=factor(clust)), size=4)+
  scale_color_discrete("Cluster")+
  coord_fixed()
```

El anterior mapa muestra una posible agrupación, según las medidas geoespaciales de la latitud y la longitud de los accidentes. Sin embargo, este agrupamiento se utiliza como referencia porque para su creación no se utilizó ningún método para la elección del $K$ óptimo.

Así que se procede a realizar una clusterización del número de accidentes por Gravedad y Barrio haciendo uso del algoritmo "k means" para la búsqueda del $K$ óptimo.

### Clusterización con Número de accidentes por Gravedad y Barrio.

Con los datos preprocesados y el subconjunto de datos que se seleccionaron, Se les realizó un escalamiento y centrado de la base de datos.

```{r}
#Numero de accidentes por Barrio
datos_cluster <- base_final03 %>% group_by(BARRIO) %>% count(name = "TOTAL_ACCIDENTES")

#Número de accidentes por barrio, según gravedad almacenado en 'df'
df <- as.matrix(table(base_final03$BARRIO, base_final03$GRAVEDAD))
df <- data.frame(Con_heridos = df[,1], Con_muertos = df[,2], Solo_danos = df[,3])

#Escalamiento y centrado de la base de datos.
scaled_data = as.matrix(scale(df))
head(scaled_data, 10)
kmm = kmeans(scaled_data, 5, nstart = 50, iter.max = 15 )

```

Para este caso, con un k=5, se evidencia que el valor de Suma de Cuadrados entre grupos (SS between) sobre la Suma de Cuadrados Totales fue de aproximadamente 85.1% (0.851), que indica un buen ajuste porque es cercano a 1. Sin embargo, es mejor graficar el WSS contra el número de clúster, ya que este número se debe especificar de antemano.

Luego se procede a hallar el k óptimo.

### El Método del Codo

```{r}
#Se fijó una semilla y se realizó el cálculo y se gráficó el WSS(total within - cluster sum of square) para k = 2 hasta k = 10
set.seed(2021022)
k.max <- 10
datos <- scaled_data
wss <- sapply(2:k.max, 
              function(k){kmeans(datos, k, nstart = 50, iter.max = 15 )$tot.withinss})
plot(2:k.max, wss, 
     type = "b", pch = 19, frame = FALSE,
     xlab = "Número de Clusters (k)",
     ylab = "WSS Total", 
     main = "Método del Codo", col="forestgreen")
```

```{r}
#Con k=5, se obtiene between_SS / total_SS =  85.1 %) almacenado en 'km'
km <- kmeans(datos, 5)
```

Según la gráfica del Método del Codo posiblemente el k=4 o k=5 serían buenos candidatos para el k óptimo, ya que presentan un cambio más suave en las pendientes en comparación con k=2 o k=3. Igualmente al observar el between SS / total SS para k=5, mencionado anteriomente, se evidencia un 85.1 %, lo cual indica un buen ajuste. Además como se graficó el WSS contra el número de clústeres, se refleja que es un buen candidato.

Después, se busca el $K$ óptimo haciendo uso del paquete NbClust, de la siguiente forma:

```{r }
nb <- NbClust(scaled_data, diss=NULL, distance = "euclidean", 
              min.nc=4, max.nc=8, method = "kmeans", 
              index = "all", alphaBeale = 0.1)
```
El cual sugiere que el $K$ óptimo es 4.


```{r }
hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])), main = "Histograma del K óptimo ", xlab = "K", ylab = "Frecuencia", col="darkorchid4")
```

Según el histograma, también indica que el $K$ óptimo es el 4.

### Resumen de Métodos

En este resumen se encuentra el método de la Silueta, el Método del Codo y Gap Statistic. Donde se obtuvieron los siguientes resultados:

### Método de la silueta.
```{r echo=FALSE, message=FALSE, warning=FALSE}
fviz_nbclust(scaled_data, kmeans, method = c("silhouette"))
```

### Método del Codo.
```{r echo=FALSE, message=FALSE, warning=FALSE}
fviz_nbclust(scaled_data, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Método del Codo")
```

###Gap Statistic
```{r }
set.seed(123)
fviz_nbclust(scaled_data, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  labs(subtitle = "Gap statistic method")
```

### Generación de clusterización, según el k óptimo.

Según los diferentes métodos $k = 4$, parecía ser muy óptimo para la generación de la clusterización.

Luego, se muestran las primeras 10 observaciones de los barrios ordenados alfabéticamente, donde se observa el tipo de gravedad y el grupo al cual pertenecen.

```{r }
kmm = kmeans(scaled_data, 4, nstart = 50, iter.max = 15 )

df_clust <- data.frame(Con_heridos = df[,1], Con_muertos = df[,2], Solo_danos = df[,3], kmm$cluster)
head(df_clust, 10)

```

Con lo realizado anteriormente poseemos el agrupamiento según el k óptimo igual a 4, es decir, ahora los barrios pertenecen a un tipo de cluster (enumaredado del 1 al 4). Para el nombramiento de cada grupo se tomó como referencia el mapa de calor, quedando de la siguiente forma:

- Grupo 1: Accidentalidad Moderada
- Grupo 2: Accidentalidad Baja
- Grupo 3: Accidentalidad Alta
- Grupo 4: Accidentalidad Media-Alta

La información que se obtuvo de cada grupo es la siguiente:

## Grupo 1 - Accidentalidad Moderada

```{r}
#Accidentalidad Moderada
dfclust_clust1 <- df_clust[df_clust$kmm.cluster == 1, ]
dfclust_clust1$total <- rowSums(dfclust_clust1[,1:3])
sum(dfclust_clust1$Con_heridos)
sum(dfclust_clust1$Con_muertos)
sum(dfclust_clust1$Solo_danos)
sum(dfclust_clust1$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 27895, la cantidad de accidentes con heridos es de 13145, la cantidad de accidentes con muertos 111 y la cantidad de accidentes con solo daños es de 14639.

## Grupo 2 - Accidentalidad Baja

```{r}
#Accidentalidad Baja
dfclust_clust2 <- df_clust[df_clust$kmm.cluster == 2, ]
dfclust_clust2$total <- rowSums(dfclust_clust2[,1:3])
sum(dfclust_clust2$Con_heridos)
sum(dfclust_clust2$Con_muertos)
sum(dfclust_clust2$Solo_danos)
sum(dfclust_clust2$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 28622, la cantidad de accidentes con heridos es de 17817, la cantidad de accidentes con muertos 106 y la cantidad de accidentes con solo daños es de 10699.

## Grupo 3 - Accidentalidad Alta

```{r}
#Accidentalidad Alta
dfclust_clust3 <- df_clust[df_clust$kmm.cluster == 3, ]
dfclust_clust3$total <- rowSums(dfclust_clust3[,1:3])
sum(dfclust_clust3$Con_heridos)
sum(dfclust_clust3$Con_muertos)
sum(dfclust_clust3$Solo_danos)
sum(dfclust_clust3$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 36247, la cantidad de accidentes con heridos es de 17147, la cantidad de accidentes con muertos 237 y la cantidad de accidentes con solo daños es de 18863.

## Grupo 4 - Accidentalidad Media-Alta

```{r}
#Accidentalidad Media-Alta
dfclust_clust4 <- df_clust[df_clust$kmm.cluster == 4, ]
dfclust_clust4$total <- rowSums(dfclust_clust4[,1:3])
sum(dfclust_clust4$Con_heridos)
sum(dfclust_clust4$Con_muertos)
sum(dfclust_clust4$Solo_danos)
sum(dfclust_clust4$total)
```

Para este grupo se observa que la cantidad total de accidentes son de 54841, la cantidad de accidentes con heridos es de 32887, la cantidad de accidentes con muertos 222 y la cantidad de accidentes con solo daños es de 21732.

Finalmente, se realizó el mapa de agrupamiento, según lo mostrado anteriormente.

## Mapa de Accidentalidad en la ciudad de Medellín por Agrupamiento

```{r}
#Se vuelve a utlizar catastro para este mapa

#Se importó el archivo .xlsx basemapa

basemapa <- read_excel("basemapa.xlsx")
base_mapa <- data_frame(basemapa)

catastro$CODIGO <- as.numeric(as.character(catastro$CODIGO))
base_mapa$Codigo <- as.numeric(as.character(base_mapa$Codigo))

#Se utilizó 'inner join' de nuevo para unir dos bases y para así luego generar mapa

mapa02 <- inner_join(catastro, base_mapa, by = c("CODIGO" = "Codigo"))

colorgrupos <- c("#00FF66", "#CCFF00", "#FF0000", "#0066FF")
mapa02$colores <- ifelse(mapa02$kmm.cluster == "1", "#00FF66",
                            ifelse(mapa02$kmm.cluster == "2", "#CCFF00",
                                   ifelse(mapa02$kmm.cluster == "3", "#FF0000",
                                          ifelse(mapa02$kmm.cluster == "4", "#0066FF",0))))

#Mapa final
leaflet() %>% addPolygons(data = mapa02, opacity = 0.4, color = "#545454",weight = 1, fillColor = mapa02$colores,
                          fillOpacity = 0.4, label = ~NOMBRE_BAR,
                          highlightOptions = highlightOptions(color = "#262626", weight = 3, bringToFront = T, opacity = 1),
                          popup = paste("Barrio: ", mapa02$NOMBRE_BAR, "<br>", "Grupo: ", mapa02$kmm.cluster, "<br>", "Número de Accidentes con heridos: ", mapa02$Con_heridos, "<br>", "Número de Accidentes con muertos: ", mapa02$Con_muertos, "<br>", "Número de Accidentes con solo daños: ", mapa02$Solo_danos)) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addLegend(position = "bottomright", colors = colorgrupos, labels = c("Grupo 1: Accidentalidad Moderada", "Grupo 2: Accidentalidad Baja", "Grupo 3: Accidentalidad Alta", "Grupo 4: Accidentalidad Media-Alta"))

```




